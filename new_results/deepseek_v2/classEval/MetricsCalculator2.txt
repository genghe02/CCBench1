```python
"""
This class provides methods to calculate Mean Reciprocal Rank (MRR) and Mean Average Precision (MAP) 
for evaluating the performance of ranking systems. These metrics are commonly used in information 
retrieval and recommendation systems.
"""

import numpy as np


class MetricsCalculator2:
    def __init__(self):
        """
        Initializes the MetricsCalculator2 class.
        """
        pass

    @staticmethod
    def mrr(data):
        """
        Calculates the Mean Reciprocal Rank (MRR) for a given set of ranked lists.

        Parameters:
            data (list or tuple): A single tuple or a list of tuples. Each tuple contains:
                - sub_list (list): A list of binary values (0 or 1) indicating the presence of a relevant item.
                - total_num (int): The total number of relevant items.

        Returns:
            tuple: A tuple containing:
                - float: The mean reciprocal rank across all provided lists.
                - list: A list of reciprocal ranks for each individual list.

        Test cases:
            # Test case 1: Single tuple with relevant items
            input_data = ([1, 0, 1], 2)
            expected_output = (0.5, [0.5])
            assert MetricsCalculator2.mrr(input_data) == expected_output

            # Test case 2: List of tuples with no relevant items
            input_data = [([0, 0, 0], 1), ([0, 0], 1)]
            expected_output = (0.0, [0.0, 0.0])
            assert MetricsCalculator2.mrr(input_data) == expected_output

            # Test case 3: Invalid input type
            input_data = "invalid"
            try:
                MetricsCalculator2.mrr(input_data)
            except Exception as e:
                assert str(e) == "the input must be a tuple([0,...,1,...],int) or a iteration of list of tuple"
        """
        if type(data) != list and type(data) != tuple:
            raise Exception("the input must be a tuple([0,...,1,...],int) or a iteration of list of tuple")

        if len(data) == 0:
            return 0.0, [0.0]
        if type(data) == tuple:
            (sub_list, total_num) = data
            sub_list = np.array(sub_list)
            if total_num == 0:
                return 0.0, [0.0]
            else:
                ranking_array = 1.0 / (np.array(list(range(len(sub_list)))) + 1)
                mr_np = sub_list * ranking_array

                mr = 0.0
                for team in mr_np:
                    if team > 0:
                        mr = team
                        break
                return mr, [mr]

        if type(data) == list:
            separate_result = []
            for (sub_list, total_num) in data:
                sub_list = np.array(sub_list)

                if total_num == 0:
                    mr = 0.0
                else:
                    ranking_array = 1.0 / (np.array(list(range(len(sub_list)))) + 1)
                    mr_np = sub_list * ranking_array

                    mr = 0.0
                    for team in mr_np:
                        if team > 0:
                            mr = team
                            break

                separate_result.append(mr)
            return np.mean(separate_result), separate_result

    @staticmethod
    def map(data):
        """
        Calculates the Mean Average Precision (MAP) for a given set of ranked lists.

        Parameters:
            data (list or tuple): A single tuple or a list of tuples. Each tuple contains:
                - sub_list (list): A list of binary values (0 or 1) indicating the presence of a relevant item.
                - total_num (int): The total number of relevant items.

        Returns:
            tuple: A tuple containing:
                - float: The mean average precision across all provided lists.
                - list: A list of average precisions for each individual list.

        Test cases:
            # Test case 1: Single tuple with relevant items
            input_data = ([1, 0, 1], 2)
            expected_output = (0.5, [0.5])
            assert MetricsCalculator2.map(input_data) == expected_output

            # Test case 2: List of tuples with no relevant items
            input_data = [([0, 0, 0], 1), ([0, 0], 1)]
            expected_output = (0.0, [0.0, 0.0])
            assert MetricsCalculator2.map(input_data) == expected_output

            # Test case 3: Invalid input type
            input_data = "invalid"
            try:
                MetricsCalculator2.map(input_data)
            except Exception as e:
                assert str(e) == "the input must be a tuple([0,...,1,...],int) or a iteration of list of tuple"
        """
        if type(data) != list and type(data) != tuple:
            raise Exception("the input must be a tuple([0,...,1,...],int) or a iteration of list of tuple")

        if len(data) == 0:
            return 0.0, [0.0]
        if type(data) == tuple:
            (sub_list, total_num) = data
            sub_list = np.array(sub_list)
            if total_num == 0:
                return 0.0, [0.0]
            else:
                ranking_array = 1.0 / (np.array(list(range(len(sub_list)))) + 1)

                right_ranking_list = []
                count = 1
                for t in sub_list:
                    if t == 0:
                        right_ranking_list.append(0)
                    else:
                        right_ranking_list.append(count)
                        count += 1

                ap = np.sum(np.array(right_ranking_list) * ranking_array) / total_num
                return ap, [ap]

        if type(data) == list:
            separate_result = []
            for (sub_list, total_num) in data:
                sub_list = np.array(sub_list)

                if total_num == 0:
                    ap = 0.0
                else:
                    ranking_array = 1.0 / (np.array(list(range(len(sub_list)))) + 1)

                    right_ranking_list = []
                    count = 1
                    for t in sub_list:
                        if t == 0:
                            right_ranking_list.append(0)
                        else:
                            right_ranking_list.append(count)
                            count += 1

                    ap = np.sum(np.array(right_ranking_list) * ranking_array) / total_num

                separate_result.append(ap)
            return np.mean(separate_result), separate_result
```