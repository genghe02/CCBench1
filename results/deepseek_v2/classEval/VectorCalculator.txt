```python
import numpy as np
from gensim import matutils
from numpy import dot, array


class VectorUtil:
    # This class provides utility functions for computing similarity measures between vectors.

    @staticmethod
    def similarity(vector_1, vector_2):
        # Compute the cosine similarity between two vectors.
        # param vector_1: numpy.ndarray, the first vector.
        # param vector_2: numpy.ndarray, the second vector.
        # return: float, the cosine similarity between the two vectors.
        # >>> VectorUtil.similarity(np.array([1, 0]), np.array([0, 1]))
        # 0.0
        # >>> VectorUtil.similarity(np.array([1, 1]), np.array([1, 1]))
        # 1.0
        return dot(matutils.unitvec(vector_1), matutils.unitvec(vector_2))

    @staticmethod
    def cosine_similarities(vector_1, vectors_all):
        # Compute the cosine similarity between a single vector and a list of vectors.
        # param vector_1: numpy.ndarray, the single vector.
        # param vectors_all: numpy.ndarray, the list of vectors.
        # return: numpy.ndarray, the cosine similarities between the single vector and each vector in the list.
        # >>> VectorUtil.cosine_similarities(np.array([1, 0]), np.array([[0, 1], [1, 1]]))
        # array([0. , 0.70710678])
        norm = np.linalg.norm(vector_1)
        all_norms = np.linalg.norm(vectors_all, axis=1)
        dot_products = dot(vectors_all, vector_1)
        similarities = dot_products / (norm * all_norms)
        return similarities

    @staticmethod
    def n_similarity(vector_list_1, vector_list_2):
        # Compute the cosine similarity between the mean vectors of two lists of vectors.
        # param vector_list_1: list of numpy.ndarray, the first list of vectors.
        # param vector_list_2: list of numpy.ndarray, the second list of vectors.
        # return: float, the cosine similarity between the mean vectors of the two lists.
        # >>> VectorUtil.n_similarity([np.array([1, 0]), np.array([0, 1])], [np.array([1, 1]), np.array([1, 1])])
        # 0.0
        # >>> VectorUtil.n_similarity([np.array([1, 1]), np.array([1, 1])], [np.array([1, 1]), np.array([1, 1])])
        # 1.0
        if not (len(vector_list_1) and len(vector_list_2)):
            raise ZeroDivisionError('At least one of the passed list is empty.')

        return dot(matutils.unitvec(array(vector_list_1).mean(axis=0)),
                   matutils.unitvec(array(vector_list_2).mean(axis=0)))

    @staticmethod
    def compute_idf_weight_dict(total_num, number_dict):
        # Compute the Inverse Document Frequency (IDF) weights for a given dictionary of counts.
        # param total_num: int, the total number of documents.
        # param number_dict: dict, a dictionary where keys are terms and values are their counts in the corpus.
        # return: dict, a dictionary where keys are terms and values are their computed IDF weights.
        # >>> VectorUtil.compute_idf_weight_dict(10, {'term1': 2, 'term2': 5})
        # {'term1': 1.3862943611198906, 'term2': 0.6931471805599453}
        index_2_key_map = {}

        index = 0

        count_list = []
        for key, count in number_dict.items():
            index_2_key_map[index] = key
            count_list.append(count)
            index = index + 1

        a = np.array(count_list)
        ## smooth, in case the divide by zero error
        a = np.log((total_num + 1) / (a + 1))
        result = {}

        for index, w in enumerate(a):
            key = index_2_key_map[index]
            result[key] = w

        return result
```