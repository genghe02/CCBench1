```python
import nltk
from nltk.stem import WordNetLemmatizer
from nltk import pos_tag, word_tokenize
import string

nltk.download('averaged_perceptron_tagger')
nltk.download('punkt')
nltk.download('wordnet')

# This class is responsible for lemmatizing sentences and extracting parts of speech from the text.
class Lemmatization:
    def __init__(self):
        # Initializes the lemmatizer to be used for lemmatizing words in a sentence.
        self.lemmatizer = WordNetLemmatizer()

    def lemmatize_sentence(self, sentence):
        # Lemmatizes the input sentence by tokenizing it, tagging the parts of speech, and applying lemmatization.
        # param sentence: str, the input sentence that needs to be lemmatized.
        # return: list, a list of lemmatized words from the sentence.
        # Examples:
        # >>> lemmatizer = Lemmatization()
        # >>> lemmatizer.lemmatize_sentence("The dogs are barking.")
        # ['The', 'dog', 'be', 'bark', '.']
        lemmatized_words = []
        sentence = self.remove_punctuation(sentence)
        words = word_tokenize(sentence)
        tagged_words = pos_tag(words)
        for word, tag in tagged_words:
            if tag.startswith('V'):
                lemmatized_word = self.lemmatizer.lemmatize(word, pos='v')
            elif tag.startswith('J'):
                lemmatized_word = self.lemmatizer.lemmatize(word, pos='a')
            elif tag.startswith('R'):
                lemmatized_word = self.lemmatizer.lemmatize(word, pos='r')
            else:
                lemmatized_word = self.lemmatizer.lemmatize(word)
            lemmatized_words.append(lemmatized_word)
        return lemmatized_words

    def get_pos_tag(self, sentence):
        # Extracts the part of speech tags for each word in the input sentence.
        # param sentence: str, the input sentence from which to extract part of speech tags.
        # return: list, a list of part of speech tags corresponding to the words in the sentence.
        # Examples:
        # >>> lemmatizer = Lemmatization()
        # >>> lemmatizer.get_pos_tag("The dogs are barking.")
        # ['DT', 'NNS', 'VBP', 'VBG', '.']
        pos_tags = []
        sentence = self.remove_punctuation(sentence)
        words = word_tokenize(sentence)
        tagged_words = pos_tag(words)
        for tagged_word in tagged_words:
            pos_tags.append(tagged_word[1])
        return pos_tags

    def remove_punctuation(self, sentence):
        # Removes punctuation from the input sentence to cleanse it before processing.
        # param sentence: str, the input sentence from which punctuation needs to be removed.
        # return: str, the cleansed sentence without punctuation.
        # Examples:
        # >>> lemmatizer = Lemmatization()
        # >>> lemmatizer.remove_punctuation("Hello, world!")
        # 'Hello world'
        return sentence.translate(str.maketrans('', '', string.punctuation))
```