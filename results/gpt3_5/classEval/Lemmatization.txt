import nltk
from nltk.stem import WordNetLemmatizer
from nltk import pos_tag, word_tokenize
import string

nltk.download('averaged_perceptron_tagger')
nltk.download('punkt')
nltk.download('wordnet')

class Lemmatization:
    # Lemmatization class to perform lemmatization on sentences.
    
    def __init__(self):
        # Constructor method to initialize the Lemmatization class.
        self.lemmatizer = WordNetLemmatizer()

    def lemmatize_sentence(self, sentence):
        # Method to lemmatize each word in a sentence.
        # param sentence: str, the input sentence to be lemmatized.
        # return: list, lemmatized words from the input sentence.
        # Test cases:
        # >>> lemmatizer = Lemmatization()
        # >>> lemmatizer.lemmatize_sentence("The quick brown foxes are jumping over the lazy dogs")
        # ['The', 'quick', 'brown', 'fox', 'be', 'jump', 'over', 'the', 'lazy', 'dog']
        lemmatized_words = []
        sentence = self.remove_punctuation(sentence)
        words = word_tokenize(sentence)
        tagged_words = pos_tag(words)
        for word, tag in tagged_words:
            if tag.startswith('V'):
                lemmatized_word = self.lemmatizer.lemmatize(word, pos='v')
            elif tag.startswith('J'):
                lemmatized_word = self.lemmatizer.lemmatize(word, pos='a')
            elif tag.startswith('R'):
                lemmatized_word = self.lemmatizer.lemmatize(word, pos='r')
            else:
                lemmatized_word = self.lemmatizer.lemmatize(word)
            lemmatized_words.append(lemmatized_word)
        return lemmatized_words

    def get_pos_tag(self, sentence):
        # Method to get the part of speech tags for words in a sentence.
        # param sentence: str, the input sentence to get POS tags.
        # return: list, POS tags for words in the sentence.
        # Test cases:
        # >>> lemmatizer = Lemmatization()
        # >>> lemmatizer.get_pos_tag("The quick brown foxes are jumping over the lazy dogs")
        # ['DT', 'JJ', 'JJ', 'NNS', 'VBP', 'VBG', 'IN', 'DT', 'JJ', 'NNS']
        pos_tags = []
        sentence = self.remove_punctuation(sentence)
        words = word_tokenize(sentence)
        tagged_words = pos_tag(words)
        for tagged_word in tagged_words:
            pos_tags.append(tagged_word[1])
        return pos_tags

    def remove_punctuation(self, sentence):
        # Method to remove punctuation from a sentence.
        # param sentence: str, the input sentence to remove punctuation.
        # return: str, sentence without punctuation.
        # Test cases:
        # >>> lemmatizer = Lemmatization()
        # >>> lemmatizer.remove_punctuation("The quick brown foxes are jumping. Over the lazy dogs!")
        # 'The quick brown foxes are jumping Over the lazy dogs'
        return sentence.translate(str.maketrans('', '', string.punctuation))