[
  "# The class calculates precision, recall, F1 score, and accuracy based on predicted and true labels.",
  "Initialize the number of all four samples to 0",
  "Update the number of all four samples(true_positives, false_positives, false_negatives, true_negatives)",
  ":param predicted_labels: list, predicted results\n        :param true_labels: list, true labels",
  ":return: None, change the number of corresponding samples",
  ">>> mc = MetricsCalculator()\n        >>> mc.update([1, 1, 0, 0], [1, 0, 0, 1])\n        (self.true_positives, self.false_positives, self.false_negatives, self.true_negatives) = (1, 1, 1, 1)",
  "Calculate precision",
  ":param predicted_labels: list, predicted results\n        :param true_labels: list, true labels",
  ":return: float",
  ">>> mc = MetricsCalculator()\n        >>> mc.precision([1, 1, 0, 0], [1, 0, 0, 1])\n        0.5",
  "Calculate recall",
  ":param predicted_labels: list, predicted results\n        :param true_labels: list, true labels",
  ":return: float",
  ">>> mc = MetricsCalculator()\n        >>> mc.recall([1, 1, 0, 0], [1, 0, 0, 1])\n        0.5",
  "Calculate f1 score, which is the harmonic mean of precision and recall",
  ":param predicted_labels: list, predicted results\n        :param true_labels: list, true labels",
  ":return: float",
  ">>> mc = MetricsCalculator()\n        >>> mc.f1_score([1, 1, 0, 0], [1, 0, 0, 1])\n        0.5",
  "Calculate accuracy",
  ":param predicted_labels: list, predicted results\n        :param true_labels: list, true labels",
  ":return: float",
  ">>> mc = MetricsCalculator()\n        >>>mc.accuracy([1, 1, 0, 0], [1, 0, 0, 1])\n        0.5"
]