[" Convert XML data to a list of URLs.", " Extract video information and download from DailyMotion.", " Download video from Sina website based on URL and additional options.", " \nGenerate colored text with ANSI escape codes.", " Convert logging function to print error messages with script name and text.", " Print a message with a specific color and style, then exit the program if an exit code is provided.", " Check and print a message with color and exit the program if an exit code is provided.", " Detect and return the operating system name based on system information.", " \u2705 Correct Output: Download videos from a specific Vimeo channel by channel ID.", " Extract information from XML data for CKPlayer API content.", " Generate a URL from a video ID using JavaScript-like logic for encoding.", " Extract and format M3U URL and segment list from a given URL.", " Normalize text for different operating systems, replacing reserved characters with '-'.", " Extract video information and download using ThePlatform API.", " Download and manage video streams based on specified parameters, including displaying stream information or downloading the stream with the best quality.", " Parse and download video content from Acfun based on video ID, title, and optional parameters.", " Convert text to list of all matches for given patterns using regular expressions.", " Convert URL query parameters to dictionary and retrieve a specific parameter value.", " Parse HTTP response content from a URL, handle gzip and deflate compression, and decode the response body to UTF-8 if specified.", " Extract and process HTTP request and response details, including handling compressed content and decoding the response body.", " Parse host information, including IP address and port, from a given string.", " Extract room ID from a given room URL key.", " Extract information from JSON content to form a title.", " \u904d\u5386\u8bfe\u7a0b\u7684\u7ae0\u8282\u548c\u90e8\u5206\uff0c\u4e0b\u8f7d\u6bcf\u4e2a\u90e8\u5206\u7684\u5185\u5bb9\u3002", " Extract information from JSON API content to download specific course topic parts using Bokecc video ID.", " Check if a task is already queued or running.", " \u6e05\u7406\u7279\u5b9a DAG ID \u7684\u4e8b\u4ef6\u7f13\u51b2\u533a\u3002", " Extract connection parameters and establish a Snowflake connection.", " Extract AWS credentials from Snowflake connection settings.", " Extract field value from extras dictionary.", " \u2705 Correct Output:\nCopy SQL data to a file.", " Convert database table to file.", " Upload file to Google Cloud Storage.", " Extract maximum partition from a Hive table based on given schema, table name, field, and filter map.", " Generate a connection configuration for MySQL using the provided connection details.", " \u83b7\u53d6\u4efb\u52a1\u72b6\u6001\u5e76\u6253\u5370\u3002", " Restart and manage Gunicorn workers based on expected number and timeout settings.", " \u2705 Correct Output:\nCheck and return the client connection if it exists, otherwise create a new one using credentials.", " Generate a summary of the code snippet that defines a method for translating text using a translation API.", " \u83b7\u53d6\u7279\u5b9a\u5b9e\u4f8b\u7684\u51fd\u6570\u3002", " Create an instance with specified parameters and wait for the operation to complete.", " Update instance properties with the given body.", " Delete Google Cloud SQL instance.", " \u83b7\u53d6\u6570\u636e\u5e93\u8fde\u63a5\u5e76\u8fd4\u56de\u7279\u5b9a\u6570\u636e\u5e93\u5b9e\u4f8b\u3002", " Create a database with specified parameters and wait for the operation to complete.", " Update database configuration.", " Delete a database from a cloud service.", " Attempt to export an instance with specified parameters and handle errors if the operation fails.", " Start the cloud SQL proxy process and monitor its output for errors or readiness messages.", " Stop and clean up the cloud_sql_proxy process, including removing the socket directory, downloaded proxy, and generated credentials file if they exist.", " Extract the version of the SQL proxy tool.", " Create a database connection and parse the connection URI.", " \u2705 Correct Output: Retrieve database connection.", " Delete connection from database if it exists, otherwise log that it was already deleted.", " \u2705 Correct Output: Retrieve CloudSqlProxyRunner instance for use in proxy mode.", " Create a database hook based on the database type (PostgreSQL or MySQL).", " Clean up database hook for PostgreSQL.", " Reserve and retrieve a free TCP port.", " Normalize ML Engine job ID by adding a prefix if it starts with a digit or a template, cleaning up 'bad' characters except templates, and ensuring only alphanumeric characters and underscores are used.", " \u2705 Correct Output: Extract error code from exception string.", " \u2705 Correct Output:\nDelete DAG runs based on specified DAG IDs.", " \u2705 Correct Output:\nClear task instances for specified DAG IDs.", " \u2705 Correct Output: Set DAGs paused state.", " Generate performance statistics for task instances in a DAG.", " Monitor and control the scheduler's heartbeat, check task instances, and manage DAGs based on their status and runtime.", " Convert XML to URL List.", " Define and configure operators for evaluating a machine learning model's predictions, including prediction, summary generation, and validation, with options for task prefix, data format, input paths, prediction path, metric function and keys, validation function, and additional Dataflow settings.", " \u521b\u5efa\u76ee\u5f55\u53ca\u5176\u6743\u9650\u8bbe\u7f6e\u3002", " Convert string to float if possible, otherwise return the original string.", " Convert naive datetime to aware datetime, setting the timezone if not provided, and handling daylight saving time (DST) transitions.", " Convert a datetime to a naive datetime by applying the specified timezone, or raise an error if the datetime is already naive.", " Convert variable arguments to datetime object with optional timezone information.", " Create a connection to the Druid broker.", " Extract HTTP connection details and configure session headers.", " Generate HTTP requests based on specified parameters and options.", " \u2705 Correct Output: Handle HTTP response and raise exceptions for non-GET/HEAD methods.", " Handle HTTP request with additional options and response checking.", " Generate a session for database operations.", " Provide a session management wrapper for functions that include a 'session' parameter.", " Reset the database by dropping all existing tables and versions.", " Generate a message for the exception details.", " Convert SQL query to fetch records from database, handling exceptions.", " Convert SQL query to a pandas DataFrame.", " Extract SQL from HQL with parameters.", " Convert rows to be inserted into a specified table with optional target fields.", " \u2705 Correct Output: Initialize CosmosDB client.", " Check if a collection exists in a specified database or the default database.", " Check if a container already exists in a database and create it if it does not exist.", " Check if a database exists by querying the database list.", " \u2705 Correct Output: Create a database if it does not already exist.", " Convert database deletion logic to handle None database name and delete the database using the connection.", " Delete a collection from a database.", " \u2705 Correct Output: Insert documents into a specified database and collection.", " \u2705 Correct Output: Delete a document from a database.", " \u83b7\u53d6\u6587\u6863\u5185\u5bb9\uff0c\u5982\u679c\u4e0d\u63d0\u4f9b\u6587\u6863ID\u5219\u629b\u51fa\u5f02\u5e38\uff0c\u5c1d\u8bd5\u4ece\u6570\u636e\u5e93\u4e2d\u8bfb\u53d6\u6587\u6863\u5e76\u8fd4\u56de\u7ed3\u679c\uff0c\u5982\u679c\u5931\u8d25\u5219\u8fd4\u56deNone\u3002", " \u2705 Correct Output:\nQuery items from a database using a SQL string.", " Extract function details from a project's function API.", " Create a new function in a specified location with given body and project ID.", " Update function with specified parameters and retries.", " Upload a function zip to Google Cloud Functions and return the upload URL.", " Delete function from a project.", " Generate statuses for task dependencies, considering context settings to ignore dependencies.", " Check if all dependencies are met for a given task.", " \u2705 Correct Output: Generate a list of failure reasons based on dependency statuses.", " Parse S3 configuration file and extract access and secret keys based on the specified format and profile.", " Extract and return credentials from the session.", " Create a connection function using the provided connection details.", " Flush the buffer and log its content if it's not empty.", " Convert file location to archive or original file based on ZIP file presence.", " Generate a list of Python file paths within a specified directory, optionally including paths from example DAGs, and handle exceptions during file examination.", " Extract TaskInstance based on DAG ID, task ID, and execution date, optionally locking for update.", " Launched DagFileProcessorManager with process ID.", " \u2705 Correct Output: Send termination message to manager.", " Exit gracefully upon receiving signal.", " Start processing files with specified parallelism and interval settings, and manage files asynchronously or synchronously based on the mode.", " Continuously checks for termination signals and processes simple DAGs in an asynchronous loop.", " Monitor agent signals and manage DAG parsing processes.", " Refresh DAG directory if the elapsed time since the last refresh exceeds the specified interval.", " Print file processing statistics if the interval since the last print exceeds the specified interval.", " Clear nonexistent import errors based on specified file paths.", " Log and display the processing statistics of DAG files, including file paths, PIDs, runtime, last runtime, and last run times.", " Update file paths and manage processors for deleted files.", " Check if all processors are done, and wait if not.", " Monitor and manage file processing tasks, including tracking running and finished processors, updating processor status, and queuing new tasks based on processing intervals and limits.", " Terminate child processes gracefully and forcefully if necessary.", " Create an SSH client for connection with specified parameters and options.", " Create a transfer job with injected project ID.", " Retrieve a transfer job by name and project ID.", " Convert XML to URL List.\nInformation for CKPlayer API content.\nConvert XML to URL List.\nInformation for CKPlayer API content.", " Update transfer job with project ID injection and execution.", " \u2705 Correct Output: Delete a transfer job.", " Cancel a transfer operation.", " Pause a transfer operation.", " Resume a transfer operation.", " Wait for a transfer job to reach a successful status with a specified timeout.", " Extract and filter TaskReschedule instances based on task instance details.", " Convert session query to count used slots in the specified pool.", " Parse and execute shell commands, capturing output and error streams.", " Remove option from configuration if it exists.", " Extract and update section information from environment variables and default settings.", " Convert XML to URL List.", " Extract transaction information from a project.", " Convert API call to commit a project.", " \u2705 Correct Output:\nPerform a lookup operation with specified keys, read consistency, and transaction.", " \u6267\u884c\u4e8b\u52a1\u56de\u6eda\u64cd\u4f5c\u3002", " Convert query execution to dictionary format.", " Extract operation details from a project using a connection.", " \u6267\u884c\u5220\u9664\u64cd\u4f5c\u5e76\u8fd4\u56de\u54cd\u5e94\u3002", " Continuously poll an operation until it is completed.", " Export data to a Google Cloud Storage bucket with optional namespace, entity filter, and labels.", " \u4ece\u5b58\u50a8\u6876\u4e2d\u5bfc\u5165\u6587\u4ef6\u7684\u51fd\u6570\uff0c\u7528\u4e8e\u6307\u5b9a\u9879\u76ee\u3001\u5b58\u50a8\u6876\u3001\u6587\u4ef6\u540d\u3001\u547d\u540d\u7a7a\u95f4\u3001\u5b9e\u4f53\u8fc7\u6ee4\u5668\u548c\u6807\u7b7e\uff0c\u901a\u8fc7\u7ba1\u7406\u8fde\u63a5\u53d1\u9001\u8bf7\u6c42\u5e76\u8fd4\u56de\u54cd\u5e94\u3002", " Convert Python function to publish a message to a target ARN using AWS SNS.", " Extract hostname from configuration or use default behavior if not available.", " Extract and return the connection to the Language Service Client if it does not exist.", " Analyzes entities in a document using the Google Cloud Natural Language API.", " \u2705 Correct Output:\nAnnotate text using the client's annotate_text method.", " \u2705 Correct Output:\nClassify text using a client connection.", " Extract template fields for a specified class in a module.", " Parse and display template field roles in a document.", " Dispose database connection pool.", " Prepare the classpath by adding necessary directories to the system path.", " Extract task result from XCom based on target task ID.", " Extract Kerberos ticket cache configuration and check for specific byte sequence.", " Convert SQLAlchemy object to dictionary, handling datetime fields by converting them to ISO format.", " Generate chunks from a list based on a specified chunk size.", " Reduce function applied to chunks of iterable with an optional initializer.", " Convert tasks in a chain to set up dependencies.", " Formats and aligns a table of data for printing.", " Generate filename based on template with Jinja2 support.", " Generate a connection object for the Dataproc API.", " Convert data processing operation to wait for completion.", " Convert various data types to strings, handling nested structures like lists, tuples, and dictionaries.", " Handle Databricks operator execution, including XCom push, run state polling, and logging.", " Execute Pig script through CLI with temporary directory and subprocess.", " Extracts the state of a Celery task, handling exceptions and timing out after 2 seconds.", " Calculate the number of tasks to be processed per send based on the synchronization parallelism.", " \u8ba1\u7b97\u6bcf\u4e2a\u540c\u6b65\u5904\u7406\u8fc7\u7a0b\u7684\u4efb\u52a1\u6570\u91cf\u3002", " Convert settings retrieval and default setting logic for a class.", " Generate an HTTP connection for ML API using authorized HTTP.", " Create and manage a job in an ML Engine project, handling existing job conflicts and logging the process.", " Retrieve job information from MLEngine, with retry mechanism for quota failures.", " Wait for a job to complete based on its state.", " Create a new version for a model in a project using ML Engine API.", " Convert XML to URL List.\nInformation for CKPlayer API content.\nSet default version for ML project.", " List versions of a model in an ML project.", " Delete a specific version of a model in a project using Google Cloud ML Engine.", " \u521b\u5efa\u6a21\u578b\u65f6\u68c0\u67e5\u6a21\u578b\u540d\u79f0\u662f\u5426\u4e3a\u7a7a\uff0c\u5e76\u8c03\u7528ML Engine API\u521b\u5efa\u6a21\u578b\u3002", " Parse and retrieve model information from ML Engine with provided project ID and model name.", " Write batch data to DynamoDB.", " Integrate plugins from Airflow's executors modules.", " Create and return a default executor based on configuration settings.", " Generate executors based on the specified executor name.", " Handle segment errors and raise an AirflowException.", " \u83b7\u53d6MSSQL\u8fde\u63a5\u5e76\u914d\u7f6e\u53c2\u6570\u3002", " Trigger a DAG with provided parameters and handle errors.", " Convert Airflow DAG deletion logic to JSON response.", " Extract task information and return it in JSON format.", " Convert API pools data to JSON format.", " Convert JSON parameters to create a pool and handle exceptions in an Airflow pipeline.", " Convert pool deletion logic to JSON response with error handling.", " Convert XML to URL List.", " Extract instance view and return current state, exit code, and detail status.", " Extract event messages from an instance view.", " Extract logs from a container.", " Delete container group.", " Check if a container exists in a resource group.", " Apply function defaults and enforce argument handling for Airflow operators.", " Construct an ingest query for Hadoop data indexing with specified parameters and configurations.", " Process messages from Redis channels and push them to XCom.", " Retrieve and filter DAG runs based on specified parameters.", " Retrieve TaskInstances based on DAG ID, execution date, and state.", " Retrieve TaskInstance object from Airflow database based on task_id, dag_id, and execution_date.", " Extract previous DAG runs based on execution date.", " Extract information from XML data to create a list of URLs.", " Update the state of a DAG considering task instances and their states.", " Verify integrity of tasks in a DAG, including handling removed or restored tasks and ensuring all tasks are present.", " Convert XML data to a list of URLs.", " Convert context to Airflow variables.", " Check and trigger DAG based on condition parameter.", " \u2705 Correct Output: Send metric data to the API with optional tags, type, and interval.", " \u274c Wrong Output (Contains code information):\ndef query_metric ( self , query , from_seconds_ago , to_seconds_ago ) : now = int ( time . time ( ) ) response = api . Metric . query ( start = now - from_seconds_ago , end = now - to_seconds_ago , query = query ) self . validate_response ( response ) return response\n\n\u2705 Correct Output:\nQuery metrics from the API within a specified time range.", " Extract and refresh DAG information from Airflow's database if the DAG is a subdag or has expired.", " Update zombie jobs in Airflow by marking them as failed and logging the status.", " Check for task cycles, resolve template files, and manage DAGs and subdags, including logging and exception handling.", " Collect DAGs from a folder, process files to find DAGs, and record statistics on DAG loading time, number of DAGs, and task numbers.", " Generate a report summarizing the DAG loading statistics.", " Convert date string to a date object and add days to it.", " Convert date string to specified format.", " Check if the specified filepath is a directory containing files matching the given regex pattern, and filter out files based on ignored extensions and file size.", " Extracts file information from an HDFS directory and filters based on specified criteria.", " Clear task instances and update their states and max_tries, then shut down related jobs and DAG runs if necessary.", " Convert state-based try number logic to return the current try number or increment it based on the state.", " Generate a command to run a specific task in Airflow with various options.", " Extract task instance state based on DAG ID, task ID, and execution date.", " Update task instance state to FAILED and log the error message.", " Update task instance information from the database.", " Clear XCom data for a specific task in a DAG.", " Extract and return the unique identifier for a task in a DAG.", " Check if all downstream tasks are done for a given task.", " Calculate the next retry datetime considering exponential backoff and maximum retry delay.", " Check if the object is ready for retry based on its state and next retry datetime.", " Check if the task pool is empty and return the result based on the availability of open slots.", " Extract and return a specific `DagRun` object based on the provided `dag_id` and `execution_date`.", " \u2705 Correct Output:\nUpdate XCom with a key-value pair for a specific task and DAG execution date.", " Extract XCom values based on task IDs, DAG ID, and execution date.", " Convert initialization context with raw flag.", " Close logging handlers and upload log to remote storage when application exits.", " Convert XML to URL List.", " \u542f\u52a8\u865a\u62df\u673a\u5b9e\u4f8b\u3002", " \u8bbe\u7f6e\u673a\u5668\u7c7b\u578b\u5e76\u7b49\u5f85\u64cd\u4f5c\u5b8c\u6210\u3002", " Convert XML data to a list of URLs.", " Convert XML to URL List.\nInformation for CKPlayer API content.\nConvert XML to URL List.\nInformation for CKPlayer API content.", " Parse XML data to extract URL list.", " Update instance group manager with a new configuration.", " Wait for an operation to complete in a specified project and zone, and handle errors or success appropriately.", " Check if a bucket exists in a storage service.", " Create and configure an S3 bucket based on the specified region or default region.", " \u68c0\u67e5\u7ed9\u5b9a\u524d\u7f00\u662f\u5426\u5b58\u5728\u4e8e\u5b58\u50a8\u6876\u4e2d\u7684\u524d\u7f00\u5217\u8868\u4e2d\u3002", " Generate a list of prefixes from a specified bucket with optional pagination parameters.", " Generate a paginated list of object keys from a specified bucket with optional prefix, delimiter, page size, and maximum items.", " \u2705 Correct Output: Check if an object exists in an S3 bucket.", " Convert XML data to a list of URLs.", " Convert XML to URL List.\nInformation for CKPlayer API content.\nConvert XML to URL List.\nInformation for CKPlayer API content.", " Generate SQL-like query for S3 object selection and handling.", " Check if a wildcard key exists in a bucket.", " \u2705 Correct Output:\nExtract wildcard key from S3 URL and match it with listed keys.", " \u2705 Correct Output: Upload file to S3 bucket with optional encryption and replacement check.", " \u2705 Correct Output:\nLoad string data into a storage system with optional encryption and replacement.", " \u2705 Correct Output: Upload bytes data to S3 bucket with optional encryption.", " \nConvert file object to S3 bucket and key, check for key existence, and upload file object to S3 with optional encryption.", " Copy object between S3 buckets with optional versioning.", " Convert XML data to a list of URLs.", " Convert user-defined data type to a dictionary.", " Generate an email with optional attachments, custom arguments, and settings for CC, BCC, and dry run.", " Extract credentials and create a connection to the SpeechClient.", " \u2705 Correct Output:\nRecognize speech from audio using Google Cloud Speech-to-Text API.", " Execute Spark SQL query with specified configurations.", " Load and initialize entry point plugins.", " Check if a plugin object is a valid subclass of AirflowPlugin and not equal to AirflowPlugin, then validate it and ensure it is not already in the list of existing plugins.", " Update task instances to skipped state and set start and end dates.", " Extract and manage connection details for an Azure Data Lake service.", " Check if a file exists in the connection with the given file path.", " \nUpload a file with multiple threads using specified parameters.", " Convert path to list of files and directories, handling wildcard (*) for globbing.", " Execute Athena query and handle its status.", " Uncompress files based on their extension, supporting only .gz and .bz2 formats.", " Parse and execute SQL queries on MSSQL database.", " Create a wrapper for CLI functions to log actions, ensuring the first positional argument is an instance of `Namespace`.", " Generate metrics for a function execution, including details such as function name, command arguments, user, and host information.", " Create cgroup directories based on the given path, logging the creation process for debugging purposes.", " Delete a cgroup tree node.", " Parse host from URL.", " Make API calls to Databricks with token or basic authentication, handling retries and exceptions.", " Convert connection details to Salesforce object.", " Convert query execution and result logging for database operations.", " Convert XML data to a list of URLs.", " Extract available fields from an object description.", " Generate Salesforce query and log it.", " Convert columns to timestamps, handling conversion errors by returning NaNs.", " Convert query results to specified formats (CSV, JSON, NDJSON) and handle timestamps, optionally recording the time of fetching.", " \u2705 Correct Output: Establish a connection to a MongoDB server with SSL options if specified.", " Retrieve a MongoDB collection from a database.", " \u6279\u91cf\u66ff\u6362\u591a\u4e2a\u6587\u6863\u5728MongoDB\u96c6\u5408\u4e2d\u3002", " Check if a mail with a specific name has attachments.", " Retrieve mail attachments by name, with optional parameters for folder, regex check, latest only, and not found mode handling.", " Download mail attachments by name, optionally checking regex and retrieving only the latest attachments, and handle cases where attachments are not found.", " Extract attachments from an email based on a name, optionally using regex for name matching, and return the first match found if specified.", " Extract file name and content from a part object.", " Convert records to Firehose delivery stream.", " Check dependency statuses for task rescheduling.", " Generate an email sending function based on configuration settings.", " Send an email with HTML content and attachments using SMTP.", " Convert datetime values to UTC timezone.", " Check if a blob exists in a container.", " Check for blobs with a specific prefix in a container.", " Convert string data to a blob in an S3 container.", " Convert file content from Azure Blob Storage.", " Delete blobs from a container, optionally by prefix or specific name, with options to ignore missing blobs or raise an exception if none are found.", " Parse and list directory contents using MLSD command with optional facts.", " Extract connection parameters and set passive mode for FTP connection.", " Convert directory listing from FTP connection.", " Retrieve file from FTP with optional callback for writing to a user-provided file or buffer.", " Convert file storage logic to handle both local file paths and file-like objects.", " Extracts and formats the modified time of a file from an FTP server, handling both cases with and without microseconds.", " Send a Discord webhook message.", " Convert XML data to a list of URLs.", " Check if a directory exists on a share.", " Check if a file exists in a specified directory on a shared network.", " List directories and files from a share.", " Create a directory on a share.", " Save file to Azure storage.", " Convert string data to a file in a specified directory on a storage share.", " \u2705 Correct Output:\nLoad stream into file from share.", " Convert XML to URL List.", " Copy object between buckets with optional destination bucket and object.", " Download file from a bucket and optionally save it to a local file.", " Upload a file to a specified bucket with optional gzip compression.", " Check if a blob exists in a specified bucket.", " Check if an object in a bucket was updated after a given timestamp.", " Delete a blob from a specified bucket.", " \u2705 Correct Output: List blobs in a specified bucket, including optional versions, maximum results, prefix, and delimiter.", " Retrieve the size of an object in a specified bucket.", " Retrieve the CRC32C checksum of an object in a specified bucket.", " Retrieve the MD5 hash of an object in a specified bucket.", " Create a bucket with specified parameters and options.", " Compose multiple source objects into a single destination object in a specified bucket.", " Check if the secondary training status has changed based on the current and previous job descriptions.", " Generate a summary of the code that processes the secondary training status message.", " \nConvert a directory or file to a compressed tarball and upload it to an S3 bucket.", " Configure S3 resources based on the provided configuration.", " Check S3 URL existence and validate bucket and key/prefix permissions.", " \nGenerate a logging connection using AWS SDK with a maximum of 15 retry attempts.", " Create a training job with configuration, optionally wait for completion, print logs, and check the interval.", " Create and execute a hyperparameter tuning job based on the provided configuration, optionally wait for completion and check the job status periodically.", " \u521b\u5efa\u5e76\u542f\u52a8\u4e00\u4e2aTransform Job\uff0c\u5e76\u7b49\u5f85\u5176\u5b8c\u6210\u3002", " Create an API endpoint with optional waiting for completion and status checking.", " Monitor and log training job status and logs from multiple streams.", " Continuously check the status of a SageMaker job until it reaches a terminal state or exceeds the maximum ingestion time.", " Implement a function to check the training status of a job with log updates, using a state machine to alternate between checking the job status and reading logs until the job completes or times out.", " Convert arguments from lowerCamelCase to snake case and execute a Python DataFlow job.", " \u6267\u884c\u79bb\u7ebf\u6570\u636e\u5e93\u8fc1\u79fb\u3002", " Generate a summary of the code content.", " \u2705 Correct Output: Delete instance based on ID and project, log if instance does not exist.", " Create an instance with specified parameters and configurations.", " Create a table with specified parameters.", " Delete a table from a Cloud SQL instance.", " Convert XML data to a list of URLs.", " Prepare CLI command for Hive execution, including options for Kerberos, Beeline, and JDBC URL formatting.", " Convert dictionary to flattened list of Hive configuration parameters.", " Load DataFrame into Hive table with inferred field types and specified parameters.", " Generate HQL statements to manage a table, including options for creating, dropping, partitioning, and loading data, with support for specifying field types, delimiters, and table properties.", " Generate a Thrift client for a metastore connection with Kerberos authentication.", " Check for a named partition in a specified schema and table.", " Check if a table exists in the database.", " \u83b7\u53d6Hive\u8fde\u63a5\uff0c\u5904\u7406\u8ba4\u8bc1\u673a\u5236\u548cKerberos\u670d\u52a1\u540d\u79f0\uff0c\u4f7f\u7528pyhive\u5e93\u8fde\u63a5Hive\u670d\u52a1\u5668\u3002", " \u274c Wrong Output (Contains code information):\nRetrieve results from Hive query with specified schema and fetch size.\n\n\u2705 Correct Output:\nRetrieve results from Hive query.", " Convert SQL query results to CSV file.", " Extract data from Hive query results.", " Convert HQL query results to a pandas DataFrame.", " \nRetrieve the client object if it exists, otherwise create a new one using the credentials.", " Convert HTTP connection details to Dingding endpoint URL.", " \u8be5\u4ee3\u7801\u5b9a\u4e49\u4e86\u4e00\u4e2a\u65b9\u6cd5\u7528\u4e8e\u53d1\u9001\u9489\u9489\u6d88\u606f\uff0c\u652f\u6301\u6587\u672c\u3001\u94fe\u63a5\u3001Markdown\u3001ActionCard\u548cFeedCard\u7c7b\u578b\u3002\u5982\u679c\u6d88\u606f\u7c7b\u578b\u4e0d\u5728\u652f\u6301\u7684\u7c7b\u578b\u5217\u8868\u4e2d\uff0c\u5219\u629b\u51faValueError\u5f02\u5e38\u3002\u6784\u5efa\u6d88\u606f\u540e\uff0c\u8bb0\u5f55\u53d1\u9001\u4fe1\u606f\u5e76\u53d1\u9001\u8bf7\u6c42\uff0c\u5982\u679c\u53d1\u9001\u5931\u8d25\u5219\u629b\u51faAirflowException\u5f02\u5e38\u3002", " Convert parameters to a format suitable for SQL operations, including escaping strings and converting None to 'NULL'.", " Escape special characters in a string.", " Convert string fields to specified types (INTEGER, FLOAT, TIMESTAMP, BOOLEAN) and handle None values.", " Validate function argument types.", " Create a BigQuery connection.", " Generate BigQuery service object.", " Check if a table exists in a dataset of a specified project using a Google Cloud BigQuery service.", " Create a table with specified parameters in BigQuery.", " Update table resource with optional parameters and patch the table in BigQuery.", " Cancel a running BigQuery job if it exists and is not already canceled.", " Delete a table from a dataset in a specified project, with an option to ignore if the table does not exist.", " Upsert operation for a table in a dataset.", " Grant dataset view access with default project settings and check for existing view access before adding.", " Extract dataset resource from BigQuery using dataset ID and project ID.", " Extract datasets list from BigQuery service based on project ID.", " Insert multiple rows into a BigQuery table.", " Convert SQL operation and parameters to a query and execute it, then store the job ID.", " Generate a summary of the code.", " Fetch and process query results from a service.", " Extract data from PostgreSQL using a defined SQL query and parameters.", " Create intermediate directories for SFTP client.", " Create a queue with specified name and attributes.", " \u2705 Correct Output: Send a message to an SQS queue.", " Parse and execute shell commands with logging and subprocess handling.", " Clean up configuration file path if it exists.", " Parse command-line arguments and set options.", " Generate HTML header with CSS and JavaScript assets only if they haven't been initialized yet.", " Create and style an SVG container with specified dimensions and styles.", " Generate JavaScript chart with default tooltip condition.", " Convert D3 axis configuration based on given parameters, including custom format, label, date format, and focus enablement.", " \u2705 Correct Output:\nCreate a Y-axis with customizable format and label.", " Convert XML data to a list of URLs.", " Generate a logging function that logs actions taken by users, including details such as the function name, task instance, owner, task ID, and DAG ID.", " Compress response data using gzip if the client accepts it.", " \nRetrieve the last DAG run based on the DAG ID, excluding externally triggered runs.", " Create a DAG run with specified parameters.", " Send a message to an SQS queue using a hook.", " Generate a JSON response with indentation for better readability.", " \u6839\u636e\u63d0\u4f9b\u7684\u4ee3\u7801\u5185\u5bb9\uff0c\u751f\u6210\u4e00\u4e2a\u7b80\u6d01\u7684\u6458\u8981\uff1a\n\n```python\ndef open_maybe_zipped(f, mode='r'):\n    _ , archive , filename = ZIP_REGEX.search(f).groups()\n    if archive and zipfile.is_zipfile(archive):\n        return zipfile.ZipFile(archive, mode=mode).open(filename)\n    else:\n        return io.open(f, mode=mode)\n```\n\n\u6458\u8981\uff1a\u6839\u636e\u6587\u4ef6\u8def\u5f84\u5339\u914d ZIP \u6587\u4ef6\uff0c\u5982\u679c\u6587\u4ef6\u662f ZIP \u538b\u7f29\u6587\u4ef6\uff0c\u5219\u6253\u5f00\u538b\u7f29\u6587\u4ef6\u4e2d\u7684\u6307\u5b9a\u6587\u4ef6\uff1b\u5426\u5219\uff0c\u76f4\u63a5\u6253\u5f00\u6587\u4ef6\u3002", " Generate a cache key based on the request path and arguments.", " \u2705 Correct Output:\nCheck and return the connection to the Video Intelligence Service.", " Annotate video using Google Cloud Video Intelligence API.", " Extract API key from connection configuration.", " \u521b\u5efaHTTP\u8fde\u63a5\u5e76\u8fd4\u56de\u4f1a\u8bdd\u5bf9\u8c61\u3002", " \u8be5\u4ee3\u7801\u5b9a\u4e49\u4e86\u4e00\u4e2a\u65b9\u6cd5\uff0c\u7528\u4e8e\u6267\u884cAPI\u8bf7\u6c42\uff0c\u5305\u62ec\u83b7\u53d6API\u5bc6\u94a5\u5e76\u5c06\u5176\u5305\u542b\u5728\u8bf7\u6c42\u5934\u4e2d\u3002", " \u6784\u5efaOpsGenie\u8d1f\u8f7d\u7684\u51fd\u6570\uff0c\u5c06\u5bf9\u8c61\u7684\u5c5e\u6027\u586b\u5145\u5230payload\u5b57\u5178\u4e2d\u3002", " Send Opsgenie alert using the provided connection ID.", " \nCheck if a connection exists and create one if it doesn't, then return the connection.", " Generate query execution ID based on provided query, context, and result configuration.", " \u2705 Correct Output:\nCheck query execution status.", " Poll query status with retry mechanism to check query execution state.", " Create a connection to an SFTP server with optional parameters for host key checking, compression, and authentication methods.", " Handle Zendesk API rate limit exception by pausing the execution for the specified number of seconds based on the \"Retry-After\" header.", " Fetch data from Zendesk API with pagination and rate limit handling.", " Generate partition information for a specified database and table with optional pagination parameters.", " Extract table information from a database.", " Extract table storage location from a database.", " Parse cluster status information from AWS cluster description.", " Delete a cluster in AWS Redshift.", " Extract and filter cluster snapshots based on their status and sort them by creation time in descending order.", " Restore cluster from snapshot.", " Create a cluster snapshot.", " \u2705 Correct Output: Execute API call with constructed parameters.", " \u2705 Correct Output: Create an EMR job flow with specified overrides.", " Filter files based on the specified file size.", " Filter files based on their extensions, ignoring specified extensions and handling copying options.", " Execute operations involving MongoDB and S3, handling pipeline and non-pipeline scenarios for data aggregation and storage.", " \u2705 Correct Output:\nRetrieve a pool by name from the database.", " \u521b\u5efa\u4e00\u4e2a\u6c60\uff08pool\uff09\uff0c\u5305\u62ec\u68c0\u67e5\u6c60\u540d\u79f0\u548c\u69fd\u4f4d\u662f\u5426\u4e3a\u7a7a\u6216\u65e0\u6548\uff0c\u5e76\u5728\u6570\u636e\u5e93\u4e2d\u6dfb\u52a0\u6216\u66f4\u65b0\u6c60\u7684\u4fe1\u606f\u3002", " Convert pool name to delete a specific pool from the database.", " Convert Python dictionary to protocol buffer.", " Wait for an operation to complete and handle its status updates.", " \u2705 Correct Output:\nRetrieve operation details for a specified project and operation name.", " Update resource labels in a cluster protocol with modified key and value.", " Create and manage a cluster for a project, converting a dictionary to a proto if necessary, and appending an airflow version label.", " Extract and return the cluster's self-link using the specified project ID, zone, and cluster name.", " Extract webhook endpoint from connection settings or provided endpoint, ensuring it matches the expected Discord webhook format.", " Generate a Discord payload with optional username, avatar URL, and TTS settings, limited to 2000 characters for the message.", " \u2705 Correct Output:\nSet up Discord webhook with proxy settings.", " Encrypt plaintext using a specified key from a Cloud KMS service, including optional authenticated data for additional security.", " \u274c Wrong Output (Contains redundant test samples, parameters, and other information):\nDefine a method to import a table with various options and parameters.\n\u2705 Correct Output:\nDefine a method to import a table with options for target directory, appending, file type, columns, where clause, direct import, driver, and extra import options.", " Generate command to import data with specified options.", " Export table to specified directory with various options.", " \nRetrieve the TextToSpeechClient instance if it exists, otherwise create a new one using the _get_credentials method.", " Generate speech from input data using a specified voice and audio configuration.", " Close method to handle logging and file operations when the application exits.", " Define and return Kubernetes init containers based on configuration settings.", " Generate environment variables for Kubernetes execution.", " Extract secrets from Kubernetes configuration and create Secret objects.", " Generate security context for Kubernetes worker based on configuration settings.", " Extract Qubole connection details and generate a URL for command execution.", " Monitor job state and update heartbeat, handle shutdown state to kill the process, and adjust sleep time based on job's latest heartbeat and configured heartrate.", " Launch a process to handle file processing with logging and ORM configuration.", " Extract and launch DagFileProcessor process for specified file path, pickle dags, and instance ID.", " Check if the process is done, handle exceptions, and manage the result queue.", " Convert signal handler to gracefully exit the program.", " Update import errors by clearing and adding errors for processed files in the session.", " Update the state of previously active DAG runs and manage their task instances.", " Update task instances' state for TI without DAG run.", " Generate a summary of the code that counts task instances by state and groups them by task ID and DAG ID.", " Change the state of executable task instances to queued.", " Enqueue task instances with queued state for execution.", " \u6267\u884c\u4efb\u52a1\u5b9e\u4f8b\u7684\u903b\u8f91\uff0c\u5305\u62ec\u67e5\u627e\u53ef\u6267\u884c\u7684\u4efb\u52a1\u5b9e\u4f8b\u3001\u6539\u53d8\u5176\u72b6\u6001\u5e76\u5c06\u5176\u5165\u961f\uff0c\u6700\u540e\u63d0\u4ea4\u4f1a\u8bdd\u3002", " Update task instances' state to scheduled if they are failed to execute.", " Update executor event buffer and manage task state based on execution status.", " Process files to retrieve and manage DAGs, handle errors, and schedule tasks.", " Update task instance status and handle different states.", " Parse and manage executor state, logging discrepancies between reported and actual task states.", " Generate a DAG run based on the provided date and session, considering max_active_runs and respecting DAG max active limit, and create a new DAG run if necessary.", " Prepare task instances for a DAG run, including handling orphaned tasks and setting their states to scheduled.", " \u2705 Correct Output: Execute tasks for specified run dates, update task instance status, and process backfill task instances.", " Update the state of unfinished DAG runs to FAILED.", " Execute a backfill job for a DAG, handling run dates, task dependencies, and executor management.", " Check heartbeat and ensure termination if processes are created later, refresh task instance from database, and handle mismatched hostnames or PIDs by logging warnings and raising exceptions.", " Extract credentials and create a client instance for the given project ID.", " Extract instance information from a client based on instance ID and project ID.", " Convert XML data to a list of URLs.", " \u2705 Correct Output: Create an instance with specified parameters.", " Update instance with specified parameters.", " \u5220\u9664\u5b9e\u4f8b\u529f\u80fd\uff0c\u652f\u6301\u6307\u5b9a\u9879\u76eeID\uff0c\u6355\u83b7API\u8c03\u7528\u9519\u8bef\u5e76\u8bb0\u5f55\u65e5\u5fd7\u3002", " Extract information from XML data to generate a list of URLs.", " Create a database instance with specified DDL statements.", " Update database with DDL statements, handling exceptions and logging results.", " Delete a database from a specified instance in a project, logging the status of the operation and handling exceptions.", " Check if an email has a specific attachment.", " Prepare additional parameters by merging them with default values, ensuring that 'image_context' is present and properly populated with 'language_hints' and 'web_detection_params' if not already provided.", " \nConvert session management logic for database connection.", " Check if a table exists in a given keyspace.", " Convert database query to check if a record exists.", " \u6784\u5efa\u8ddf\u8e2a\u9a71\u52a8\u7a0b\u5e8f\u72b6\u6001\u7684\u547d\u4ee4\uff0c\u5305\u62ec\u83b7\u53d6Spark\u4e8c\u8fdb\u5236\u8def\u5f84\u3001\u8fde\u63a5\u4e3b\u8282\u70b9\u548c\u9a71\u52a8\u7a0b\u5e8fID\uff0c\u5982\u679c\u6ca1\u6709\u9a71\u52a8\u7a0b\u5e8fID\u5219\u629b\u51fa\u5f02\u5e38\u3002", " Submit Spark application with specified parameters and environment variables, and handle return code and driver status tracking.", " Extract application and driver pod IDs from Spark submit logs for cluster mode, and track driver status and exit code.", " Extract and process Spark driver status logs.", " Create a task runner based on the specified type.", " Wait for AWS Batch job completion with exponential backoff and retry mechanism.", " Extract data from MySQL database using a defined SQL query.", " Convert XML to URL List.\nInformation for CKPlayer API content.\nConvert XML to URL List.\nInformation for CKPlayer API content.", " Generate a local schema file based on database cursor information and save it as a temporary file.", " Generate a dictionary of column types based on the schema provided.", " Convert MySQL field types to Python type hints.", " Execute Sqoop operations based on command type (export or import), handling table or query parameters, and configuring additional options as needed.", " \u5b9a\u4e49\u4e00\u4e2a\u88c5\u9970\u5668\u51fd\u6570 `apply_lineage`\uff0c\u7528\u4e8e\u5728\u8c03\u7528\u76ee\u6807\u51fd\u6570\u65f6\u8bb0\u5f55\u540e\u7aef\u3001\u8f93\u5165\u548c\u8f93\u51fa\u7aef\u53e3\u7684\u4fe1\u606f\uff0c\u5e76\u5c06\u8fd9\u4e9b\u4fe1\u606f\u901a\u8fc7 `xcom_push` \u63a8\u9001\u5230 Airflow \u7684 XCom \u4e2d\uff0c\u6700\u540e\u8c03\u7528\u540e\u7aef\u7684 `send_lineage` \u65b9\u6cd5\u3002", " Convert JSON string to dictionary, handling exceptions for failed parsing.", " Generate date ranges based on specified parameters.", " Convert time units from seconds to minutes, hours, or days.", " Convert XML data to a list of URLs.", " Initialize role with given name, VMs, and permissions, ensuring permissions are set based on the provided VMs and permissions.", " Delete role if it exists in the database and log the deletion.", " \u2705 Correct Output:\nRetrieve user roles based on the authenticated state.", " Generate a set of all permission-view pairs for the user's roles.", " Check if the user has any of the specified roles.", " Check if a user has a specific permission for a view menu.", " Clean faulty permissions and log the number of deleted entries.", " Merge permission and view menu associations.", " Update admin permissions based on view menus.", " Update DAG view permissions based on access control settings.", " Convert global logical DAG permissions for all DAG VMs.", " Attempt to create a Fernet object for encryption or decryption based on configuration settings, handling cases where cryptography is not available or configuration settings are invalid.", " \u2705 Correct Output:\nUpdate table name and log information for database and table.", " \u2705 Correct Output:\nRetrieve AWS Glue Catalog Hook.", " Process SQS messages and delete them if successful, otherwise raise an exception.", " Extract connection details from HDFS and manage client connections based on configuration.", " Attempt to establish a connection to an HDFS cluster by checking available connections and attempting to use them to create a client object, logging debug information and raising an exception if all connections fail.", " Check if a path exists in HDFS.", " Convert file upload process from HDFS.", " \u83b7\u53d6\u4e0e Pinot \u4ee3\u7406\u7684\u8fde\u63a5\u3002", " Generate a URI based on connection details.", " Convert date to dictionary format.", " Convert time to dictionary format.", " Extract and initialize a Redis connection object.", " \u274c Wrong Output (Contains code information):\nConvert SQL query to pandas DataFrame.\n\n\u2705 Correct Output:\nConvert SQL query to pandas DataFrame.", " Execute SQL statements with optional parameters and automatic commit handling.", " Set the auto-commit mode for a database connection.", " Insert rows into a database table with optional target fields and commit options.", " Convert Python function to serialize cell data, handling datetime and None values.", " Check scheduler health status and return the result in JSON format.", " Extract URL based on DAG ID, task ID, and execution date, handling errors if the DAG or task is not found or if no URL is available.", " \u83b7\u53d6\u4e91\u6570\u636e\u5e93\u8fde\u63a5\u5e76\u8fdb\u884c\u9a8c\u8bc1\u3002", " Send a message via Slack using the provided webhook details.", " Retrieve and manage credentials for Google services based on specified configurations or default settings.", " Parse and authorize HTTP requests using Google Auth.", " Catch HTTP exceptions and handle them appropriately, logging errors and raising Airflow exceptions when necessary.", " Ensure that positional arguments are not used in the method and handle project ID either through a keyword argument or extra in GCP connection definition.", " Convert class states to a list.", " Prepare Spark SQL command with various configurations and options.", " Convert image to tensor format.", " Normalize a tensor image with given mean and standard deviation.", " Convert image resizing function, handling different size formats and interpolation methods.", " Pad an image with a specified padding and fill value, supporting different padding modes.", " Convert image using PIL Image.", " Convert image by resizing and cropping.", " Convert PIL Image to horizontally flipped version.", " Convert image perspective based on given start and end points with optional bicubic interpolation.", " Convert image to vertical flip using PIL.", " Generate a function to perform five crops on an image with the specified size.", " Convert image brightness by adjusting the factor.", " Convert image contrast based on a given factor.", " Convert image saturation by a given factor.", " Adjust the hue of a PIL Image by a specified factor.", " Adjust image gamma with optional gain parameter.", " \u2705 Correct Output:\nRotate PIL Image with specified angle and optional parameters.", " Generate an affine transformation for a PIL Image, including handling of rotation, translation, scaling, and shearing, with optional resampling and fill color specification.", " Convert image to grayscale or to three channels based on the specified number of output channels.", " Save a tensor as an image with specified parameters.", " Parse directory to find classes and their indices.", " Convert image files to numpy arrays and extract patches from them.", " Convert information from a file into a tensor of long integers.", " Read and parse match files, extracting relevant information and converting it into a tensor format.", " Calculate the top-k accuracy of model predictions.", " Convert code to handle distributed setup with master-only print functionality.", " Download and save a file from a given URL with optional MD5 checksum verification.", " Convert directory list to absolute paths if the prefix option is enabled.", " \nList files in a directory based on suffix and optionally with prefix.", " Convert XML to URL List.", " \u2705 Correct Output: Generate random parameters for image resizing.", " Generate random distorted corners and endpoints for image processing.", " Generate random parameters for image resizing and cropping.", " Adjust image brightness, contrast, saturation, and hue based on given parameters.", " Generate random parameters for image transformations including angle, translations, scale, and shear.", " \u2705 Correct Output: Download and extract files from a specified URL and local file, handling individual photo downloads with error handling for potential issues.", " Download and process data files from URLs, check existence, and save processed data as torch files.", " Download and extract a zip archive, process EMNIST data, and save it as torch files.", " Extract theme name from request arguments or preferences, or use a default theme if the requested theme is not available.", " Generate a summary of the code that converts XML data to a list of URLs and extracts information from CKPlayer API content.", " Save and render user preferences, including image proxy settings, language, disabled engines, allowed plugins, and engine statistics.", " Convert directory contents to list of themes, excluding the '__common__' directory.", " Generate search queries based on specific prefixes or categories.", " Parse and format currency conversion results from a JSON response.", " Define a custom gradient function for TensorFlow computations, which stops gradient computation based on a manually controlled flag and ensures the shapes of input gradients match the input variables.", " Convert arguments to a multivariate normal distribution using TensorFlow Probability.", " Define a joint log probability function for eight schools using hierarchical Bayesian modeling, involving normal distributions for average effect, average standard deviation, school effects, and treatment effects.", " Benchmark for eight-schools problem using Hamiltonian Monte Carlo sampling.", " \nConvert a function's docstring by replacing placeholders with provided values.", " Extract and simplify the name from a distribution string.", " Convert a custom random variable (RV) builder function to expose the name as a dummy keyword argument.", " Generate a custom random variable based on the given distribution, sample shape, and value.", " Generate a random variable for a given distribution class, handling sample shape and value parameters, and preserving the original docstring.", " Generate predictive values based on a model using time series data and parameter samples.", " Generate forecasts using a state-space model with parameter samples and observed time series.", " Convert array to maximum values with non-finite values masked to a specified value.", " Convert and assert finite values in TensorFlow.", " \nEnsures the tensor's rank is at most a specified value.", " Convert event shape to its size by multiplying the dimensions if the shape is statically known, otherwise use TensorFlow to reduce the product of the event shape.", " Generate a function to evaluate all one-hot encoded distributions by reshaping and permuting the identity matrix.", " Convert-to-tensor function identifier interpretation and deserialization.", " Calculate the total size of parameters for a mixture model.", " \u5b9e\u73b0\u4e00\u4e2a\u83b7\u53d6\u4e0b\u4e00\u4e2a\u62e6\u622a\u5668\u7684\u51fd\u6570\uff0c\u4f7f\u7528\u5806\u6808\u6765\u7ba1\u7406\u62e6\u622a\u5668\u3002", " Convert function to interceptable with wrapper.", " Records function execution to a tape and stores the results in an ordered dictionary.", " Generate synthetic logistic regression data with specified parameters.", " Generate a visualization of decision boundaries for given features, labels, true weights and biases, and candidate weights and biases, then save the figure as a PNG file.", " Create a training input pipeline using TensorFlow.", " Check the validity of map_values based on specified conditions and return a list of assertions.", " Perform MCMC trace with specified number of steps and trace function.", " Convert function call based on argument type and structure.", " Convert a function and its arguments to a tuple containing the function's return value, extra outputs, and gradients.", " Convert structure from one format to another, ensuring the number of elements matches the target structure.", " Transform log probability function with bijectors and optional initial state.", " Perform LeapFrog step for Hamiltonian Monte Carlo with specified step size, target log probability function, and kinetic energy function.", " Perform a Metropolis-Hastings step to update the state, considering the energy change and generating a random number to decide acceptance.", " \u8be5\u51fd\u6570\u5b9e\u73b0\u4e86\u4e00\u4e2a\u57fa\u4e8e\u54c8\u5bc6\u987f\u8499\u7279\u5361\u6d1b\u65b9\u6cd5\u7684\u72b6\u6001\u91c7\u6837\u5668\uff0c\u7528\u4e8e\u4ece\u76ee\u6807\u5bf9\u6570\u6982\u7387\u51fd\u6570\u4e2d\u91c7\u6837\u72b6\u6001\u3002\u5b83\u5305\u62ec\u521d\u59cb\u5316\u72b6\u6001\u3001\u8ba1\u7b97\u52a8\u80fd\u3001\u8fdb\u884c\u86d9\u8df3\u7b97\u6cd5\u3001\u5e94\u7528Metropolis-Hastings\u6b65\u9aa4\u4ee5\u53ca\u8fd4\u56de\u6700\u7ec8\u72b6\u6001\u548c\u63a5\u53d7\u6982\u7387\u3002", " Implement a control adaptation function using a nested structure of floating-point tensors and a specified adaptation rate.", " Convert configuration settings to appropriate function handlers using deserialization.", " Convert input to TensorFlow tensor if not None.", " Create a scale operator with identity multiplier, diagonal, lower triangular, perturbation diagonal, perturbation factor, shift, validation arguments, and data type.", " Adds a normal perturbation to the input state in a Markov chain, with optional scaling and naming scope.", " Adds a uniform perturbation to the input state, with a specified scale, to the Markov chain.", " Convert tensor to match the event rank.", " Calculate the entropy lower bound for a distribution.", " \u2705 Correct Output:\nCalculate categorical probabilities based on log probabilities or regular probabilities.", " Validate function arguments for TensorFlow operations.", " Ensure TensorFlow installation and check for compatible version.", " \u2705 Correct Output:\nImplement logistic regression model using TensorFlow and Edward.", " Normalize features and append a column of ones for the intercept, then convert features to TensorFlow float32 type and binarize outcomes based on a specific category.", " Calculate the Cholesky decomposition of the covariance matrix for a given tensor.", " Calculate the standard deviation of a tensor along a specified axis, with optional name scope and dimension handling.", " Calculate the variance of a tensor along specified axes.", " Generate a function to ensure axis values are positive for tensors or lists, adjusting negative values to their positive counterparts within the tensor's dimensions.", " \nConvert tensor to squeezed form based on specified axis.", " Convert TensorFlow code to standardize input data.", " Convert TensorFlow operation to reconstruct values.", " Generate a 2x2 transition matrix for a semilocal linear trend model, incorporating the batch shape of the autoregressive coefficients.", " Generate noise for a semi-local linear trend transition model with a specified level scale, slope mean, slope scale, and autoregressive coefficient."]