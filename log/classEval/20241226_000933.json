{"response body": "ChatCompletion(id='chatcmpl-AiOElHcULwPoqJhHQwFjmEnum64F7', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='\"\"\"\\nThis class implements a Metrics Calculator for Mean Reciprocal Rank (MRR) and Mean Average Precision (MAP) calculation.\\n\\n\"\"\"\\n\\nimport numpy as np\\n\\n\\nclass MetricsCalculator:\\n    def __init__(self):\\n        \"\"\"\\n        Initializes the Metrics Calculator.\\n        \"\"\"\\n        pass\\n\\n    @staticmethod\\n    def mrr(data):\\n        \"\"\"\\n        Calculate the Mean Reciprocal Rank (MRR) from the given data.\\n\\n        Parameters:\\n            data (list or tuple): A list of tuples containing a sublist of relevance values and the total number of items.\\n\\n        Returns:\\n            tuple: A tuple containing the MRR value and a list of separate MRR values for each data entry.\\n\\n        Test cases:\\n            # Test case 1: Normal usage\\n            assert mrr([(0.9, 1), (0.8, 2)]) == (0.7571428571428571, [0.9, 0.7571428571428571])\\n            \\n            # Test case 2: Edge case with empty data\\n            assert mrr([]) == (0.0, [0.0])\\n            \\n            # Test case 3: Error case with incorrect input type\\n            try:\\n                mrr(123)\\n            except Exception as e:\\n                assert str(e) == \"the input must be a tuple([0,...,1,...],int) or an iteration of a list of tuples\"\\n        \"\"\"\\n\\n        if type(data) != list and type(data) != tuple:\\n            raise Exception(\"the input must be a tuple([0,...,1,...],int) or an iteration of a list of tuples\")\\n\\n        if len(data) == 0:\\n            return 0.0, [0.0]\\n        \\n        if type(data) == tuple:\\n            (sub_list, total_num) = data\\n            sub_list = np.array(sub_list)\\n            \\n            if total_num == 0:\\n                return 0.0, [0.0]\\n            else:\\n                ranking_array = 1.0 / (np.array(list(range(len(sub_list))) + 1)\\n                mr_np = sub_list * ranking_array\\n\\n                mr = next((team for team in mr_np if team > 0), 0.0)\\n                \\n                return mr, [mr]\\n\\n        if type(data) == list:\\n            separate_result = []\\n            for (sub_list, total_num) in data:\\n                sub_list = np.array(sub_list)\\n\\n                if total_num == 0:\\n                    mr = 0.0\\n                else:\\n                    ranking_array = 1.0 / (np.array(list(range(len(sub_list))) + 1)\\n                    mr_np = sub_list * ranking_array\\n                    mr = next((team for team in mr_np if team > 0), 0.0)\\n\\n                separate_result.append(mr)\\n            \\n            return np.mean(separate_result), separate_result\\n\\n    @staticmethod\\n    def map(data):\\n        \"\"\"\\n        Calculate the Mean Average Precision (MAP) from the given data.\\n\\n        Parameters:\\n            data (list or tuple): A list of tuples containing a sublist of relevance values and the total number of items.\\n            \\n        Returns:\\n            tuple: A tuple containing the MAP value and a list of separate MAP values for each data entry.\\n\\n        Test cases:\\n            # Test case 1: Normal usage\\n            assert map([(1, 3), (0, 2)]) == (0.8333333333333334, [1.0, 0.6666666666666666])\\n\\n            # Test case 2: Edge case with empty data\\n            assert map([]) == (0.0, [0.0])\\n            \\n            # Test case 3: Error case with incorrect input type\\n            try:\\n                map(456)\\n            except Exception as e:\\n                assert str(e) == \"the input must be a tuple([0,...,1,...],int) or an iteration of a list of tuples\"\\n        \"\"\"\\n\\n        if type(data) != list and type(data) != tuple:\\n            raise Exception(\"the input must be a tuple([0,...,1,...],int) or an iteration of a list of tuples\")\\n\\n        if len(data) == 0:\\n            return 0.0, [0.0]\\n        \\n        if type(data) == tuple:\\n            (sub_list, total_num) = data\\n            sub_list = np.array(sub_list)\\n            \\n            if total_num == 0:\\n                return 0.0, [0.0]\\n            else:\\n                ranking_array = 1.0 / (np.array(list(range(len(sub_list))) + 1)\\n\\n                right_ranking_list = [r if r != 0 else 0 for r in range(1, len(sub_list) + 1)]\\n                ap = np.sum(np.array(right_ranking_list) * ranking_array) / total_num\\n                \\n                return ap, [ap]\\n\\n        if type(data) == list:\\n            separate_result = []\\n            for (sub_list, total_num) in data:\\n                sub_list = np.array(sub_list)\\n\\n                if total_num == 0:\\n                    ap = 0.0\\n                else:\\n                    ranking_array = 1.0 / (np.array(list(range(len(sub_list))) + 1)\\n\\n                    right_ranking_list = [r if r != 0 else 0 for r in range(1, len(sub_list) + 1)]\\n                    ap = np.sum(np.array(right_ranking_list) * ranking_array) / total_num\\n\\n                separate_result.append(ap)\\n                \\n            return np.mean(separate_result), separate_result\\n', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1735142963, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=1160, prompt_tokens=1760, total_tokens=2920, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))", "test_case_name": "MetricsCalculator2.txt"}