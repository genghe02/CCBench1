{"response body": "ChatCompletion(id='chatcmpl-AiM4Z0QkdoVnWcX8ysvGJALv5Gxw9', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```python\\n\"\"\"\\nThis class provides utility methods for vector operations, including similarity measurements and inverse document frequency calculations.\\n\"\"\"\\n\\nimport numpy as np\\nfrom gensim import matutils\\nfrom numpy import dot, array\\n\\nclass VectorUtil:\\n    @staticmethod\\n    def similarity(vector_1, vector_2):\\n        \"\"\"\\n        Calculate the cosine similarity between two vectors.\\n\\n        Parameters:\\n            vector_1 (array-like): The first vector for similarity measurement.\\n            vector_2 (array-like): The second vector for similarity measurement.\\n\\n        Returns:\\n            float: Cosine similarity value between the two vectors, ranging from -1 (opposite) to 1 (exactly the same).\\n\\n        Test cases:\\n            # Test case 1: Positive similarity\\n            vector_a = [1, 2, 3]\\n            vector_b = [1, 2, 3]\\n            expected_output = 1.0\\n            assert VectorUtil.similarity(vector_a, vector_b) == expected_output\\n\\n            # Test case 2: No similarity\\n            vector_c = [0, 0, 0]\\n            vector_d = [1, 1, 1]\\n            expected_output = 0.0\\n            assert VectorUtil.similarity(vector_c, vector_d) == expected_output\\n\\n            # Test case 3: Negative similarity\\n            vector_e = [1, 1, 1]\\n            vector_f = [-1, -1, -1]\\n            expected_output = -1.0\\n            assert VectorUtil.similarity(vector_e, vector_f) == expected_output\\n        \"\"\"\\n        return dot(matutils.unitvec(vector_1), matutils.unitvec(vector_2))\\n\\n    @staticmethod\\n    def cosine_similarities(vector_1, vectors_all):\\n        \"\"\"\\n        Calculate the cosine similarities between a single vector and an array of vectors.\\n\\n        Parameters:\\n            vector_1 (array-like): The vector for which to compute similarities.\\n            vectors_all (array-like): A collection of vectors to compare against.\\n\\n        Returns:\\n            array: An array of cosine similarity values between vector_1 and each vector in vectors_all.\\n\\n        Test cases:\\n            # Test case 1: Multiple comparisons\\n            vector_a = [1, 0, 0]\\n            vectors_b = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\\n            expected_output = [1.0, 0.0, 0.0]\\n            assert np.allclose(VectorUtil.cosine_similarities(vector_a, vectors_b), expected_output)\\n\\n            # Test case 2: All vectors pointing in the same direction\\n            vector_c = [1, 1, 1]\\n            vectors_d = [[1, 1, 1], [0, 0, 0], [2, 2, 2]]\\n            expected_output = [1.0, 0.0, 1.0]\\n            assert np.allclose(VectorUtil.cosine_similarities(vector_c, vectors_d), expected_output)\\n\\n            # Test case 3: Zero vector scenario\\n            vector_e = [0, 0, 0]\\n            vectors_f = [[1, 1, 1]]\\n            expected_output = [0.0]\\n            assert np.allclose(VectorUtil.cosine_similarities(vector_e, vectors_f), expected_output)\\n        \"\"\"\\n        norm = np.linalg.norm(vector_1)\\n        all_norms = np.linalg.norm(vectors_all, axis=1)\\n        dot_products = dot(vectors_all, vector_1)\\n        similarities = dot_products / (norm * all_norms)\\n        return similarities\\n\\n    @staticmethod\\n    def n_similarity(vector_list_1, vector_list_2):\\n        \"\"\"\\n        Calculate the normalized similarity between two lists of vectors.\\n\\n        Parameters:\\n            vector_list_1 (list of array-like): The first list of vectors.\\n            vector_list_2 (list of array-like): The second list of vectors.\\n\\n        Returns:\\n            float: Similarity score between the average vectors of the two lists.\\n\\n        Raises:\\n            ZeroDivisionError: If at least one of the input lists is empty.\\n\\n        Test cases:\\n            # Test case 1: Normal lists\\n            vectors_a = [[1, 0], [0, 1]]\\n            vectors_b = [[1, 1], [2, 2]]\\n            expected_output = 0.7071067811865475  # Cosine similarity of mean vectors\\n            assert np.isclose(VectorUtil.n_similarity(vectors_a, vectors_b), expected_output)\\n\\n            # Test case 2: One empty vector list\\n            with pytest.raises(ZeroDivisionError):\\n                VectorUtil.n_similarity([], [[1, 1]])\\n\\n            # Test case 3: Both empty vector lists\\n            with pytest.raises(ZeroDivisionError):\\n                VectorUtil.n_similarity([], [])\\n        \"\"\"\\n        if not (len(vector_list_1) and len(vector_list_2)):\\n            raise ZeroDivisionError(\\'At least one of the passed list is empty.\\')\\n\\n        return dot(matutils.unitvec(array(vector_list_1).mean(axis=0)),\\n                   matutils.unitvec(array(vector_list_2).mean(axis=0)))\\n\\n    @staticmethod\\n    def compute_idf_weight_dict(total_num, number_dict):\\n        \"\"\"\\n        Compute the inverse document frequency (IDF) weights for a given dictionary of term frequencies.\\n\\n        Parameters:\\n            total_num (int): Total number of documents.\\n            number_dict (dict): A dictionary mapping terms to their frequency counts.\\n\\n        Returns:\\n            dict: A dictionary mapping terms to their IDF weight.\\n\\n        Test cases:\\n            # Test case 1: Normal scenario\\n            total_documents = 5\\n            term_frequencies = {\\'term1\\': 1, \\'term2\\': 2}\\n            expected_output = {\\'term1\\': 0.22314355131420976, \\'term2\\': 0.15611923673829033}\\n            assert VectorUtil.compute_idf_weight_dict(total_documents, term_frequencies) == expected_output\\n\\n            # Test case 2: Empty frequency dictionary\\n            expected_output = {}\\n            assert VectorUtil.compute_idf_weight_dict(1, {}) == expected_output\\n\\n            # Test case 3: Smoothing with zero frequency\\n            total_documents = 3\\n            term_frequencies = {\\'term3\\': 0}\\n            expected_output = {\\'term3\\': 1.0986122886681098}\\n            assert VectorUtil.compute_idf_weight_dict(total_documents, term_frequencies) == expected_output\\n        \"\"\"\\n        index_2_key_map = {}\\n\\n        index = 0\\n\\n        count_list = []\\n        for key, count in number_dict.items():\\n            index_2_key_map[index] = key\\n            count_list.append(count)\\n            index = index + 1\\n\\n        a = np.array(count_list)\\n        # Smooth in case of divide by zero error\\n        a = np.log((total_num + 1) / (a + 1))\\n        result = {}\\n\\n        for index, w in enumerate(a):\\n            key = index_2_key_map[index]\\n            result[key] = w\\n\\n        return result\\n```', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1735134643, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier=None, system_fingerprint='fp_0aa8d3e20b', usage=CompletionUsage(completion_tokens=1488, prompt_tokens=1713, total_tokens=3201, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))", "test_case_name": "VectorCalculator.txt"}