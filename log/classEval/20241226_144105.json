{"response body": "{\n  \"id\": \"e6679d20-0a39-4f27-bbfc-44dae3134629\",\n  \"choices\": [\n    {\n      \"finish_reason\": \"stop\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"message\": {\n        \"content\": \"```python\\n\\\"\\\"\\\"\\nThis class provides utility functions for vector operations, including similarity calculations and IDF weight computations.\\n\\\"\\\"\\\"\\n\\nimport numpy as np\\nfrom gensim import matutils\\nfrom numpy import dot, array\\n\\n\\nclass VectorUtil:\\n    @staticmethod\\n    def similarity(vector_1, vector_2):\\n        \\\"\\\"\\\"\\n        Computes the cosine similarity between two vectors.\\n\\n        Parameters:\\n            vector_1 (array-like): The first vector.\\n            vector_2 (array-like): The second vector.\\n\\n        Returns:\\n            float: The cosine similarity between the two vectors, ranging from -1 to 1.\\n\\n        Test cases:\\n            # Test case 1: Identical vectors\\n            assert VectorUtil.similarity([1, 0], [1, 0]) == 1.0\\n\\n            # Test case 2: Orthogonal vectors\\n            assert VectorUtil.similarity([1, 0], [0, 1]) == 0.0\\n\\n            # Test case 3: Opposite vectors\\n            assert VectorUtil.similarity([1, 0], [-1, 0]) == -1.0\\n        \\\"\\\"\\\"\\n        return dot(matutils.unitvec(vector_1), matutils.unitvec(vector_2))\\n\\n    @staticmethod\\n    def cosine_similarities(vector_1, vectors_all):\\n        \\\"\\\"\\\"\\n        Computes the cosine similarities between a single vector and a list of vectors.\\n\\n        Parameters:\\n            vector_1 (array-like): The single vector.\\n            vectors_all (array-like): The list of vectors to compare against.\\n\\n        Returns:\\n            array-like: An array of cosine similarities between the single vector and each vector in the list.\\n\\n        Test cases:\\n            # Test case 1: Single vector and list of identical vectors\\n            assert np.allclose(VectorUtil.cosine_similarities([1, 0], [[1, 0], [1, 0]]), [1.0, 1.0])\\n\\n            # Test case 2: Single vector and list of orthogonal vectors\\n            assert np.allclose(VectorUtil.cosine_similarities([1, 0], [[0, 1], [0, 1]]), [0.0, 0.0])\\n\\n            # Test case 3: Single vector and list of opposite vectors\\n            assert np.allclose(VectorUtil.cosine_similarities([1, 0], [[-1, 0], [-1, 0]]), [-1.0, -1.0])\\n        \\\"\\\"\\\"\\n        norm = np.linalg.norm(vector_1)\\n        all_norms = np.linalg.norm(vectors_all, axis=1)\\n        dot_products = dot(vectors_all, vector_1)\\n        similarities = dot_products / (norm * all_norms)\\n        return similarities\\n\\n    @staticmethod\\n    def n_similarity(vector_list_1, vector_list_2):\\n        \\\"\\\"\\\"\\n        Computes the cosine similarity between the mean vectors of two lists of vectors.\\n\\n        Parameters:\\n            vector_list_1 (list of array-like): The first list of vectors.\\n            vector_list_2 (list of array-like): The second list of vectors.\\n\\n        Returns:\\n            float: The cosine similarity between the mean vectors of the two lists.\\n\\n        Raises:\\n            ZeroDivisionError: If at least one of the lists is empty.\\n\\n        Test cases:\\n            # Test case 1: Lists with identical mean vectors\\n            assert VectorUtil.n_similarity([[1, 0], [1, 0]], [[1, 0], [1, 0]]) == 1.0\\n\\n            # Test case 2: Lists with orthogonal mean vectors\\n            assert VectorUtil.n_similarity([[1, 0], [1, 0]], [[0, 1], [0, 1]]) == 0.0\\n\\n            # Test case 3: Empty list\\n            try:\\n                VectorUtil.n_similarity([], [[1, 0]])\\n            except ZeroDivisionError as e:\\n                assert str(e) == 'At least one of the passed list is empty.'\\n        \\\"\\\"\\\"\\n        if not (len(vector_list_1) and len(vector_list_2)):\\n            raise ZeroDivisionError('At least one of the passed list is empty.')\\n\\n        return dot(matutils.unitvec(array(vector_list_1).mean(axis=0)),\\n                   matutils.unitvec(array(vector_list_2).mean(axis=0)))\\n\\n    @staticmethod\\n    def compute_idf_weight_dict(total_num, number_dict):\\n        \\\"\\\"\\\"\\n        Computes the IDF (Inverse Document Frequency) weights for a given dictionary of term counts.\\n\\n        Parameters:\\n            total_num (int): The total number of documents.\\n            number_dict (dict): A dictionary where keys are terms and values are the counts of documents containing each term.\\n\\n        Returns:\\n            dict: A dictionary where keys are terms and values are the IDF weights for each term.\\n\\n        Test cases:\\n            # Test case 1: Single term\\n            assert VectorUtil.compute_idf_weight_dict(10, {'term1': 1}) == {'term1': np.log(11 / 2)}\\n\\n            # Test case 2: Multiple terms\\n            result = VectorUtil.compute_idf_weight_dict(10, {'term1': 1, 'term2': 5})\\n            expected = {'term1': np.log(11 / 2), 'term2': np.log(11 / 6)}\\n            assert all(np.isclose(result[key], expected[key]) for key in result)\\n\\n            # Test case 3: Zero counts\\n            result = VectorUtil.compute_idf_weight_dict(10, {'term1': 0, 'term2': 0})\\n            expected = {'term1': np.log(11 / 1), 'term2': np.log(11 / 1)}\\n            assert all(np.isclose(result[key], expected[key]) for key in result)\\n        \\\"\\\"\\\"\\n        index_2_key_map = {}\\n\\n        index = 0\\n\\n        count_list = []\\n        for key, count in number_dict.items():\\n            index_2_key_map[index] = key\\n            count_list.append(count)\\n            index = index + 1\\n\\n        a = np.array(count_list)\\n        ## smooth, in case the divide by zero error\\n        a = np.log((total_num + 1) / (a + 1))\\n        result = {}\\n\\n        for index, w in enumerate(a):\\n            key = index_2_key_map[index]\\n            result[key] = w\\n\\n        return result\\n```\",\n        \"role\": \"assistant\"\n      }\n    }\n  ],\n  \"created\": 1735195247,\n  \"model\": \"deepseek-chat\",\n  \"object\": \"chat.completion\",\n  \"system_fingerprint\": \"fp_1a5c54ff19\",\n  \"usage\": {\n    \"completion_tokens\": 1370,\n    \"prompt_tokens\": 1470,\n    \"total_tokens\": 2840,\n    \"prompt_cache_hit_tokens\": 960,\n    \"prompt_cache_miss_tokens\": 510\n  }\n}", "test_case_name": "VectorCalculator.txt"}