{"response body": {"id": "d7804c7e-fdd3-48ac-b884-01f90bd5895f", "object": "chat.completion", "model": "gpt-35-turbo", "created": "2024-09-23 13:53:29", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "content": "import nltk\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk import pos_tag, word_tokenize\nimport string\n\nnltk.download('averaged_perceptron_tagger')\nnltk.download('punkt')\nnltk.download('wordnet')\n\nclass Lemmatization:\n    # Lemmatization class to perform lemmatization on sentences.\n    \n    def __init__(self):\n        # Constructor method to initialize the Lemmatization class.\n        self.lemmatizer = WordNetLemmatizer()\n\n    def lemmatize_sentence(self, sentence):\n        # Method to lemmatize each word in a sentence.\n        # param sentence: str, the input sentence to be lemmatized.\n        # return: list, lemmatized words from the input sentence.\n        # Test cases:\n        # >>> lemmatizer = Lemmatization()\n        # >>> lemmatizer.lemmatize_sentence(\"The quick brown foxes are jumping over the lazy dogs\")\n        # ['The', 'quick', 'brown', 'fox', 'be', 'jump', 'over', 'the', 'lazy', 'dog']\n        lemmatized_words = []\n        sentence = self.remove_punctuation(sentence)\n        words = word_tokenize(sentence)\n        tagged_words = pos_tag(words)\n        for word, tag in tagged_words:\n            if tag.startswith('V'):\n                lemmatized_word = self.lemmatizer.lemmatize(word, pos='v')\n            elif tag.startswith('J'):\n                lemmatized_word = self.lemmatizer.lemmatize(word, pos='a')\n            elif tag.startswith('R'):\n                lemmatized_word = self.lemmatizer.lemmatize(word, pos='r')\n            else:\n                lemmatized_word = self.lemmatizer.lemmatize(word)\n            lemmatized_words.append(lemmatized_word)\n        return lemmatized_words\n\n    def get_pos_tag(self, sentence):\n        # Method to get the part of speech tags for words in a sentence.\n        # param sentence: str, the input sentence to get POS tags.\n        # return: list, POS tags for words in the sentence.\n        # Test cases:\n        # >>> lemmatizer = Lemmatization()\n        # >>> lemmatizer.get_pos_tag(\"The quick brown foxes are jumping over the lazy dogs\")\n        # ['DT', 'JJ', 'JJ', 'NNS', 'VBP', 'VBG', 'IN', 'DT', 'JJ', 'NNS']\n        pos_tags = []\n        sentence = self.remove_punctuation(sentence)\n        words = word_tokenize(sentence)\n        tagged_words = pos_tag(words)\n        for tagged_word in tagged_words:\n            pos_tags.append(tagged_word[1])\n        return pos_tags\n\n    def remove_punctuation(self, sentence):\n        # Method to remove punctuation from a sentence.\n        # param sentence: str, the input sentence to remove punctuation.\n        # return: str, sentence without punctuation.\n        # Test cases:\n        # >>> lemmatizer = Lemmatization()\n        # >>> lemmatizer.remove_punctuation(\"The quick brown foxes are jumping. Over the lazy dogs!\")\n        # 'The quick brown foxes are jumping Over the lazy dogs'\n        return sentence.translate(str.maketrans('', '', string.punctuation))"}}], "usage": {"completion_tokens": 703, "prompt_tokens": 1001, "total_tokens": 1704}, "feeType": "1", "consume": 0.01129349228}, "test_case_name": "Lemmatization.txt"}