{"response body": "ChatCompletion(id='chatcmpl-A6GR5iVRlEsddnsJosehLsRBQ3TAy', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```python\\nimport numpy as np\\n\\n# This class provides methods to calculate various metrics such as Mean Reciprocal Rank (MRR) and Mean Average Precision (MAP) from given data.\\nclass MetricsCalculator2:\\n    def __init__(self):\\n        pass\\n\\n    @staticmethod\\n    def mrr(data):\\n        # Calculate the Mean Reciprocal Rank (MRR) from the provided data.\\n        # :param data: Union[list, tuple], data can be a list of tuples or a single tuple containing a list and an integer.\\n        # :return: tuple, (mean reciprocal rank as a float, list of individual MRR values).\\n        # >>> MetricsCalculator2.mrr(([1, 0, 0], 3))  # returns (1.0, [1.0])\\n        # >>> MetricsCalculator2.mrr(([0, 0, 0], 3))  # returns (0.0, [0.0])\\n        # >>> MetricsCalculator2.mrr(([1, 0, 1], 3))  # returns (0.5, [0.5])\\n        if type(data) != list and type(data) != tuple:\\n            raise Exception(\"the input must be a tuple([0,...,1,...],int) or a iteration of list of tuple\")\\n\\n        if len(data) == 0:\\n            return 0.0, [0.0]\\n        if type(data) == tuple:\\n            (sub_list, total_num) = data\\n            sub_list = np.array(sub_list)\\n            if total_num == 0:\\n                return 0.0, [0.0]\\n            else:\\n                ranking_array = 1.0 / (np.array(list(range(len(sub_list)))) + 1)\\n                mr_np = sub_list * ranking_array\\n\\n                mr = 0.0\\n                for team in mr_np:\\n                    if team > 0:\\n                        mr = team\\n                        break\\n                return mr, [mr]\\n\\n        if type(data) == list:\\n            separate_result = []\\n            for (sub_list, total_num) in data:\\n                sub_list = np.array(sub_list)\\n\\n                if total_num == 0:\\n                    mr = 0.0\\n                else:\\n                    ranking_array = 1.0 / (np.array(list(range(len(sub_list)))) + 1)\\n                    mr_np = sub_list * ranking_array\\n\\n                    mr = 0.0\\n                    for team in mr_np:\\n                        if team > 0:\\n                            mr = team\\n                            break\\n\\n                separate_result.append(mr)\\n            return np.mean(separate_result), separate_result\\n\\n    @staticmethod\\n    def map(data):\\n        # Calculate the Mean Average Precision (MAP) from the provided data.\\n        # :param data: Union[list, tuple], data can be a list of tuples or a single tuple containing a list and an integer.\\n        # :return: tuple, (mean average precision as a float, list of individual AP values).\\n        # >>> MetricsCalculator2.map(([1, 0, 0], 3))  # returns (0.5, [0.5])\\n        # >>> MetricsCalculator2.map(([0, 0, 0], 3))  # returns (0.0, [0.0])\\n        # >>> MetricsCalculator2.map(([1, 1, 1], 3))  # returns (1.0, [1.0])\\n        if type(data) != list and type(data) != tuple:\\n            raise Exception(\"the input must be a tuple([0,...,1,...],int) or a iteration of list of tuple\")\\n\\n        if len(data) == 0:\\n            return 0.0, [0.0]\\n        if type(data) == tuple:\\n            (sub_list, total_num) = data\\n            sub_list = np.array(sub_list)\\n            if total_num == 0:\\n                return 0.0, [0.0]\\n            else:\\n                ranking_array = 1.0 / (np.array(list(range(len(sub_list)))) + 1)\\n\\n                right_ranking_list = []\\n                count = 1\\n                for t in sub_list:\\n                    if t == 0:\\n                        right_ranking_list.append(0)\\n                    else:\\n                        right_ranking_list.append(count)\\n                        count += 1\\n\\n                ap = np.sum(np.array(right_ranking_list) * ranking_array) / total_num\\n                return ap, [ap]\\n\\n        if type(data) == list:\\n            separate_result = []\\n            for (sub_list, total_num) in data:\\n                sub_list = np.array(sub_list)\\n\\n                if total_num == 0:\\n                    ap = 0.0\\n                else:\\n                    ranking_array = 1.0 / (np.array(list(range(len(sub_list)))) + 1)\\n\\n                    right_ranking_list = []\\n                    count = 1\\n                    for t in sub_list:\\n                        if t == 0:\\n                            right_ranking_list.append(0)\\n                        else:\\n                            right_ranking_list.append(count)\\n                            count += 1\\n\\n                    ap = np.sum(np.array(right_ranking_list) * ranking_array) / total_num\\n\\n                separate_result.append(ap)\\n            return np.mean(separate_result), separate_result\\n```', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1726056511, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier=None, system_fingerprint='fp_483d39d857', usage=CompletionUsage(completion_tokens=1096, prompt_tokens=1515, total_tokens=2611))", "test_case_name": "MetricsCalculator2.txt"}