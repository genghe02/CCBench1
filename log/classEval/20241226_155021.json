{"response body": {"id": "7fab81d3-200f-4e22-bfa2-13df9d460552", "object": "chat.completion", "model": "gpt-4-32k", "created": "2024-12-26 15:50:24", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "content": "\"\"\"\nThis class provides methods to calculate the Cohen's Kappa and Fleiss' Kappa, which are statistical measures of inter-rater reliability.\n\"\"\"\n\nimport numpy as np\n\n\nclass KappaCalculator:\n\n    @staticmethod\n    def kappa(testData, k):\n        \"\"\"\n        Calculates the Cohen's Kappa for the given data.\n\n        Parameters:\n            testData (list): a 2D list where each element is a row of ratings.\n            k (int): the number of raters.\n        \n        Returns:\n            float: the Cohen's Kappa calculated from the data.\n        \n        Test cases:\n            # Test case 1: Normal case\n            data = [[1, 0], [0, 1]]\n            assert kappa(data, 2) == 1.0\n\n            # Test case 2: Edge case (all ratings are the same)\n            data = [[1, 1], [1, 1]]\n            assert kappa(data, 2) == 1.0\n\n            # Test case 3: Error case (inconsistent number of ratings)\n            data = [[1, 0, 1], [0, 1]]\n            assert kappa(data, 2) raises ValueError\n        \"\"\"\n\n        dataMat = np.mat(testData)\n        P0 = 0.0\n        for i in range(k):\n            P0 += dataMat[i, i] * 1.0\n        xsum = np.sum(dataMat, axis=1)\n        ysum = np.sum(dataMat, axis=0)\n        sum = np.sum(dataMat)\n        Pe = float(ysum * xsum) / sum / sum\n        P0 = float(P0 / sum * 1.0)\n        cohens_coefficient = float((P0 - Pe) / (1 - Pe))\n        return cohens_coefficient\n\n    @staticmethod\n    def fleiss_kappa(testData, N, k, n):\n        \"\"\"\n        Calculates the Fleiss' Kappa for the given data.\n\n        Parameters:\n            testData (list): a 2D list where each element is a row of ratings.\n            N (int): the number of subjects.\n            k (int): the number of categories.\n            n (int): the number of ratings per subject.\n        \n        Returns:\n            float: the Fleiss' Kappa calculated from the data.\n        \n        Test cases:\n            # Test case 1: Normal case\n            data = [[1, 0], [0, 1]]\n            assert fleiss_kappa(data, 2, 2, 1) == 1.0\n\n            # Test case 2: Edge case (all ratings are the same)\n            data = [[1, 1], [1, 1]]\n            assert fleiss_kappa(data, 2, 2, 1) == 1.0\n\n            # Test case 3: Error case (inconsistent number of ratings)\n            data = [[1, 0, 1], [0, 1]]\n            assert fleiss_kappa(data, 2, 2, 1) raises ValueError\n        \"\"\"\n\n        dataMat = np.mat(testData, float)\n        oneMat = np.ones((k, 1))\n        sum = 0.0\n        P0 = 0.0\n        for i in range(N):\n            temp = 0.0\n            for j in range(k):\n                sum += dataMat[i, j]\n                temp += 1.0 * dataMat[i, j] ** 2\n            temp -= n\n            temp /= (n - 1) * n\n            P0 += temp\n        P0 = 1.0 * P0 / N\n        ysum = np.sum(dataMat, axis=0)\n        for i in range(k):\n            ysum[0, i] = (ysum[0, i] / sum) ** 2\n        Pe = ysum * oneMat * 1.0\n        ans = (P0 - Pe) / (1 - Pe)\n        return ans[0, 0]"}}], "usage": {"completion_tokens": 861, "prompt_tokens": 1407, "total_tokens": 2268}, "feeType": "1", "consume": 1.364244}, "test_case_name": "KappaCalculator.txt"}