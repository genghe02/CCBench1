{"response body": {"id": "f432e124-1d1c-498b-975c-2ee9f585cc18", "object": "chat.completion", "model": "gpt-4-32k", "created": "2024-12-26 15:54:40", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "content": "\"\"\"\nThis class provides methods to calculate the Mean Reciprocal Rank (MRR) and Mean Average Precision (MAP) metrics.\n\"\"\"\n\nimport numpy as np\n\n\nclass MetricsCalculator2:\n    def __init__(self):\n        \"\"\"\n        Initialize the MetricsCalculator2 class.\n        \"\"\"\n        pass\n\n    @staticmethod\n    def mrr(data):\n        \"\"\"\n        Calculate the Mean Reciprocal Rank (MRR) of the given data.\n        \n        Parameters:\n            data (list/tuple): A list of tuples or a single tuple, where each tuple contains a binary array and total number.\n            The binary array should have 1s at the position of relevant items and 0s elsewhere. The total number is the total\n            number of relevant items.\n        \n        Returns:\n            (float, list): A tuple containing the MRR and a list of individual Reciprocal Ranks.\n        \n        Test cases:\n            # Test case 1: Single tuple with one relevant item\n            assert mrr(([0, 0, 1, 0], 1)) == (1.0, [1.0])\n            \n            # Test case 2: List of tuples with multiple relevant items\n            assert mrr([([0, 0, 1, 0], 1), ([0, 1, 0, 0], 1)]) == (0.75, [1.0, 0.5])\n            \n            # Test case 3: Input with no relevant items\n            assert mrr(([0, 0, 0, 0], 0)) == (0.0, [0.0])\n        \"\"\"\n        if type(data) != list and type(data) != tuple:\n            raise Exception(\"The input must be a tuple([0,...,1,...],int) or a iteration of list of tuple\")\n\n        if len(data) == 0:\n            return 0.0, [0.0]\n        if type(data) == tuple:\n            (sub_list, total_num) = data\n            sub_list = np.array(sub_list)\n            if total_num == 0:\n                return 0.0, [0.0]\n            else:\n                ranking_array = 1.0 / (np.array(list(range(len(sub_list)))) + 1)\n                mr_np = sub_list * ranking_array\n\n                mr = 0.0\n                for team in mr_np:\n                    if team > 0:\n                        mr = team\n                        break\n                return mr, [mr]\n\n        if type(data) == list:\n            separate_result = []\n            for (sub_list, total_num) in data:\n                sub_list = np.array(sub_list)\n\n                if total_num == 0:\n                    mr = 0.0\n                else:\n                    ranking_array = 1.0 / (np.array(list(range(len(sub_list)))) + 1)\n                    mr_np = sub_list * ranking_array\n\n                    mr = 0.0\n                    for team in mr_np:\n                        if team > 0:\n                            mr = team\n                            break\n\n                separate_result.append(mr)\n            return np.mean(separate_result), separate_result\n\n    @staticmethod\n    def map(data):\n        \"\"\"\n        Calculate the Mean Average Precision (MAP) of the given data.\n        \n        Parameters:\n            data (list/tuple): A list of tuples or a single tuple, where each tuple contains a binary array and total number.\n            The binary array should have 1s at the position of relevant items and 0s elsewhere. The total number is the total\n            number of relevant items.\n        \n        Returns:\n            (float, list): A tuple containing the MAP and a list of individual Average Precisions.\n        \n        Test cases:\n            # Test case 1: Single tuple with one relevant item\n            assert map(([0, 0, 1, 0], 1)) == (1.0, [1.0])\n            \n            # Test case 2: List of tuples with multiple relevant items\n            assert map([([0, 0, 1, 0], 1), ([0, 1, 0, 0], 1)]) == (0.75, [1.0, 0.5])\n            \n            # Test case 3: Input with no relevant items\n            assert map(([0, 0, 0, 0], 0)) == (0.0, [0.0])\n\n        \"\"\"\n        if type(data) != list and type(data) != tuple:\n            raise Exception(\"The input must be a tuple([0,...,1,...],int) or a iteration of list of tuple\")\n\n        if len(data) == 0:\n            return 0.0, [0.0]\n        if type(data) == tuple:\n            (sub_list, total_num) = data\n            sub_list = np.array(sub_list)\n            if total_num == 0:\n                return 0.0, [0.0]\n            else:\n                ranking_array = 1.0 / (np.array(list(range(len(sub_list)))) + 1)\n\n                right_ranking_list = []\n                count = 1\n                for t in sub_list:\n                    if t == 0:\n                        right_ranking_list.append(0)\n                    else:\n                        right_ranking_list.append(count)\n                        count += 1\n\n                ap = np.sum(np.array(right_ranking_list) * ranking_array) / total_num\n                return ap, [ap]\n\n        if type(data) == list:\n            separate_result = []\n            for (sub_list, total_num) in data:\n                sub_list = np.array(sub_list)\n\n                if total_num == 0:\n                    ap = 0.0\n                else:\n                    ranking_array = 1.0 / (np.array(list(range(len(sub_list)))) + 1)\n\n                    right_ranking_list = []\n                    count = 1\n                    for t in sub_list:\n                        if t == 0:\n                            right_ranking_list.append(0)\n                        else:\n                            right_ranking_list.append(count)\n                            count += 1\n\n                    ap = np.sum(np.array(right_ranking_list) * ranking_array) / total_num\n\n                separate_result.append(ap)\n            return np.mean(separate_result), separate_result"}}], "usage": {"completion_tokens": 1309, "prompt_tokens": 1760, "total_tokens": 3069}, "feeType": "1", "consume": 1.908808}, "test_case_name": "MetricsCalculator2.txt"}