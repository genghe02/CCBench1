{"response body": "{\n  \"id\": \"8af13c53-b21d-4b26-a5cc-120f354cd3c3\",\n  \"choices\": [\n    {\n      \"finish_reason\": \"stop\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"message\": {\n        \"content\": \"```python\\n\\\"\\\"\\\"\\nThis class provides methods to calculate Cohen's Kappa and Fleiss' Kappa, which are statistical measures of inter-rater agreement for categorical items.\\n\\\"\\\"\\\"\\n\\nimport numpy as np\\n\\n\\nclass KappaCalculator:\\n\\n    @staticmethod\\n    def kappa(testData, k):\\n        \\\"\\\"\\\"\\n        Calculate Cohen's Kappa coefficient for inter-rater agreement.\\n\\n        Parameters:\\n            testData (list of list of int): A confusion matrix where testData[i][j] represents the number of times \\n                                           category i was assigned by rater 1 and category j by rater 2.\\n            k (int): The number of categories or classes.\\n\\n        Returns:\\n            float: Cohen's Kappa coefficient, a value between -1 and 1. \\n                  A value of 1 indicates perfect agreement, 0 indicates agreement by chance, \\n                  and negative values indicate disagreement.\\n\\n        Test cases:\\n            # Test case 1: Perfect agreement\\n            testData = [[10, 0], [0, 10]]\\n            k = 2\\n            assert KappaCalculator.kappa(testData, k) == 1.0\\n\\n            # Test case 2: Agreement by chance\\n            testData = [[5, 5], [5, 5]]\\n            k = 2\\n            assert KappaCalculator.kappa(testData, k) == 0.0\\n\\n            # Test case 3: Disagreement\\n            testData = [[0, 10], [10, 0]]\\n            k = 2\\n            assert KappaCalculator.kappa(testData, k) == -1.0\\n        \\\"\\\"\\\"\\n        dataMat = np.mat(testData)\\n        P0 = 0.0\\n        for i in range(k):\\n            P0 += dataMat[i, i] * 1.0\\n        xsum = np.sum(dataMat, axis=1)\\n        ysum = np.sum(dataMat, axis=0)\\n        sum = np.sum(dataMat)\\n        Pe = float(ysum * xsum) / sum / sum\\n        P0 = float(P0 / sum * 1.0)\\n        cohens_coefficient = float((P0 - Pe) / (1 - Pe))\\n        return cohens_coefficient\\n\\n    @staticmethod\\n    def fleiss_kappa(testData, N, k, n):\\n        \\\"\\\"\\\"\\n        Calculate Fleiss' Kappa coefficient for inter-rater agreement.\\n\\n        Parameters:\\n            testData (list of list of int): A matrix where testData[i][j] represents the number of raters \\n                                           who assigned category j to subject i.\\n            N (int): The number of subjects.\\n            k (int): The number of categories.\\n            n (int): The number of raters.\\n\\n        Returns:\\n            float: Fleiss' Kappa coefficient, a value between -1 and 1. \\n                  A value of 1 indicates perfect agreement, 0 indicates agreement by chance, \\n                  and negative values indicate disagreement.\\n\\n        Test cases:\\n            # Test case 1: Perfect agreement\\n            testData = [[10, 0, 0], [0, 10, 0], [0, 0, 10]]\\n            N = 3\\n            k = 3\\n            n = 10\\n            assert KappaCalculator.fleiss_kappa(testData, N, k, n) == 1.0\\n\\n            # Test case 2: Agreement by chance\\n            testData = [[3, 3, 4], [3, 3, 4], [3, 3, 4]]\\n            N = 3\\n            k = 3\\n            n = 10\\n            assert KappaCalculator.fleiss_kappa(testData, N, k, n) == 0.0\\n\\n            # Test case 3: Disagreement\\n            testData = [[0, 10, 0], [0, 0, 10], [10, 0, 0]]\\n            N = 3\\n            k = 3\\n            n = 10\\n            assert KappaCalculator.fleiss_kappa(testData, N, k, n) == -1.0\\n        \\\"\\\"\\\"\\n        dataMat = np.mat(testData, float)\\n        oneMat = np.ones((k, 1))\\n        sum = 0.0\\n        P0 = 0.0\\n        for i in range(N):\\n            temp = 0.0\\n            for j in range(k):\\n                sum += dataMat[i, j]\\n                temp += 1.0 * dataMat[i, j] ** 2\\n            temp -= n\\n            temp /= (n - 1) * n\\n            P0 += temp\\n        P0 = 1.0 * P0 / N\\n        ysum = np.sum(dataMat, axis=0)\\n        for i in range(k):\\n            ysum[0, i] = (ysum[0, i] / sum) ** 2\\n        Pe = ysum * oneMat * 1.0\\n        ans = (P0 - Pe) / (1 - Pe)\\n        return ans[0, 0]\\n```\",\n        \"role\": \"assistant\"\n      }\n    }\n  ],\n  \"created\": 1735194382,\n  \"model\": \"deepseek-chat\",\n  \"object\": \"chat.completion\",\n  \"system_fingerprint\": \"fp_1a5c54ff19\",\n  \"usage\": {\n    \"completion_tokens\": 1094,\n    \"prompt_tokens\": 1419,\n    \"total_tokens\": 2513,\n    \"prompt_cache_hit_tokens\": 960,\n    \"prompt_cache_miss_tokens\": 459\n  }\n}", "test_case_name": "KappaCalculator.txt"}