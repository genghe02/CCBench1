{"response body": {"id": "7588880a-ca77-4d68-a59b-b8bc25304705", "object": "chat.completion", "model": "gpt-35-turbo", "created": "2024-09-23 13:55:10", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "content": "```python\nimport numpy as np\nfrom gensim import matutils\nfrom numpy import dot, array\n\nclass VectorUtil:\n    # This is a class that provides utility functions for vector operations.\n\n    @staticmethod\n    def similarity(vector_1, vector_2):\n        # Calculate the cosine similarity between two vectors.\n        # param vector_1: Vector 1 for comparison\n        # param vector_2: Vector 2 for comparison\n        # return: float, cosine similarity between the two vectors\n        # Some test cases for the function:\n        # vector_1 = [1, 0, 1]\n        # vector_2 = [0, 1, 0]\n        # similarity = VectorUtil.similarity(vector_1, vector_2)\n        return dot(matutils.unitvec(vector_1), matutils.unitvec(vector_2))\n\n    @staticmethod\n    def cosine_similarities(vector_1, vectors_all):\n        # Calculate cosine similarities between a vector and a list of vectors.\n        # param vector_1: Vector for comparison\n        # param vectors_all: List of vectors to compare with\n        # return: numpy array, cosine similarities between the vector and all vectors in vectors_all\n        # Some test cases for the function:\n        # vector_1 = [1, 0, 1]\n        # vectors_all = [[0, 1, 0], [1, 1, 0], [1, 0, 0]]\n        # similarities = VectorUtil.cosine_similarities(vector_1, vectors_all)\n        norm = np.linalg.norm(vector_1)\n        all_norms = np.linalg.norm(vectors_all, axis=1)\n        dot_products = dot(vectors_all, vector_1)\n        similarities = dot_products / (norm * all_norms)\n        return similarities\n\n    @staticmethod\n    def n_similarity(vector_list_1, vector_list_2):\n        # Calculate the cosine similarity between the means of two lists of vectors.\n        # param vector_list_1: List of vectors 1 for comparison\n        # param vector_list_2: List of vectors 2 for comparison\n        # return: float, cosine similarity between the means of the two lists of vectors\n        # Some test cases for the function:\n        # vector_list_1 = [[1, 0, 1], [0, 1, 0]]\n        # vector_list_2 = [[1, 1, 0], [0, 0, 1]]\n        # similarity = VectorUtil.n_similarity(vector_list_1, vector_list_2)\n        if not (len(vector_list_1) and len(vector_list_2)):\n            raise ZeroDivisionError('At least one of the passed lists is empty.')\n\n        return dot(matutils.unitvec(array(vector_list_1).mean(axis=0)),\n                   matutils.unitvec(array(vector_list_2).mean(axis=0))\n\n    @staticmethod\n    def compute_idf_weight_dict(total_num, number_dict):\n        # Compute IDF weights for elements in a dictionary.\n        # param total_num: Total number of elements in the dictionary\n        # param number_dict: Dictionary containing element counts\n        # return: dict, IDF weights for elements in the dictionary\n        # Some test cases for the function:\n        # total_num = 10\n        # number_dict = {'apple': 5, 'banana': 3, 'orange': 2}\n        # weight_dict = VectorUtil.compute_idf_weight_dict(total_num, number_dict)\n        index_2_key_map = {}\n\n        index = 0\n\n        count_list = []\n        for key, count in number_dict.items():\n            index_2_key_map[index] = key\n            count_list.append(count)\n            index = index + 1\n\n        a = np.array(count_list)\n        ## smooth, in case the divide by zero error\n        a = np.log((total_num + 1) / (a + 1))\n        result = {}\n\n        for index, w in enumerate(a):\n            key = index_2_key_map[index]\n            result[key] = w\n\n        return result\n```"}}], "usage": {"completion_tokens": 862, "prompt_tokens": 1040, "total_tokens": 1902}, "feeType": "1", "consume": 0.013167267848}, "test_case_name": "VectorCalculator.txt"}