{"response body": "ChatCompletion(id='chatcmpl-AihgEDzLv7ftw9y3Mps0Y7HA0TiXF', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='\"\"\"\\nThe class provides utility functions for working with vectors, including computing similarity metrics and weights.\\n\\nVectorUtil:\\n    This class contains static methods for various vector operations.\\n\\nMethods:\\n    1. similarity(vector_1, vector_2)\\n    2. cosine_similarities(vector_1, vectors_all)\\n    3. n_similarity(vector_list_1, vector_list_2)\\n    4. compute_idf_weight_dict(total_num, number_dict)\\n\"\"\"\\n\\nimport numpy as np\\nfrom gensim import matutils\\nfrom numpy import dot, array\\n\\n\\nclass VectorUtil:\\n    @staticmethod\\n    def similarity(vector_1, vector_2):\\n        \"\"\"\\n        Compute the cosine similarity between two vectors.\\n\\n        Parameters:\\n            vector_1 (numpy.ndarray): First vector\\n            vector_2 (numpy.ndarray): Second vector\\n\\n        Returns:\\n            float: Cosine similarity between the two input vectors\\n\\n        Test Cases:\\n            # Test case 1: orthogonal vectors\\n            assert similarity([1, 0], [0, 1]) == 0.0\\n            \\n            # Test case 2: identical vectors\\n            assert similarity([1, 2, 3], [1, 2, 3]) == 1.0\\n            \\n            # Test case 3: opposite direction vectors\\n            assert similarity([1, 0], [-1, 0]) == -1.0\\n        \"\"\"\\n        return dot(matutils.unitvec(vector_1), matutils.unitvec(vector_2))\\n\\n    @staticmethod\\n    def cosine_similarities(vector_1, vectors_all):\\n        \"\"\"\\n        Compute cosine similarity between a vector and a list of vectors.\\n\\n        Parameters:\\n            vector_1 (numpy.ndarray): Reference vector\\n            vectors_all (numpy.ndarray): List of vectors to compare against\\n\\n        Returns:\\n            numpy.ndarray: Array of cosine similarities between vector_1 and vectors_all\\n\\n        Test Cases:\\n            # Test case 1: single vector similarity\\n            assert all(cosine_similarities([1, 0], [[1, 0], [0, 1]]) == [1.0, 0.0])\\n            \\n            # Test case 2: vector not in the list\\n            assert all(cosine_similarities([1, 1], [[0, 1], [2, 2]]) == [0.70710678, 0.92387953])\\n            \\n            # Test case 3: empty input list\\n            assert cosine_similarities([0, 0], []) == []\\n        \"\"\"\\n        norm = np.linalg.norm(vector_1)\\n        all_norms = np.linalg.norm(vectors_all, axis=1)\\n        dot_products = dot(vectors_all, vector_1)\\n        similarities = dot_products / (norm * all_norms)\\n        return similarities\\n\\n    @staticmethod\\n    def n_similarity(vector_list_1, vector_list_2):\\n        \"\"\"\\n        Calculate the average cosine similarity between two lists of vectors.\\n\\n        Parameters:\\n            vector_list_1 (list): List of vectors\\n            vector_list_2 (list): List of vectors to compare with\\n\\n        Returns:\\n            float: Average cosine similarity between the two lists of vectors\\n\\n        Test Cases:\\n            # Test case 1: identical vector lists\\n            assert n_similarity([[1, 0], [0, 1]], [[1, 0], [0, 1]]) == 1.0\\n            \\n            # Test case 2: opposite direction vector lists\\n            assert n_similarity([[1, 0], [-1, 0]], [[-1, 0], [1, 0]]) == -1.0\\n            \\n            # Test case 3: empty vector list\\n            assert n_similarity([], []) == None\\n        \"\"\"\\n        if not (len(vector_list_1) and len(vector_list_2)):\\n            raise ZeroDivisionError(\\'At least one of the passed lists is empty.\\')\\n        \\n        return dot(matutils.unitvec(array(vector_list_1).mean(axis=0)),\\n                   matutils.unitvec(array(vector_list_2).mean(axis=0)))\\n\\n    @staticmethod\\n    def compute_idf_weight_dict(total_num, number_dict):\\n        \"\"\"\\n        Calculate inverse document frequency (IDF) weights.\\n\\n        Parameters:\\n            total_num (int): Total number of documents\\n            number_dict (dict): Dictionary mapping index/ID to term frequency\\n\\n        Returns:\\n            dict: Dictionary containing IDF weights for each term\\n\\n        Test Cases:\\n            # Test case 1: basic IDF calculation\\n            assert compute_idf_weight_dict(100, {\\'term1\\': 10, \\'term2\\': 5}) == {\\'term1\\': 2.30258509, \\'term2\\': 3.912023005 }\\n            \\n            # Test case 2: zero frequency term\\n            assert compute_idf_weight_dict(100, {\\'term1\\': 0, \\'term2\\': 1}) == {\\'term1\\': 4.60517019, \\'term2\\': 2.30258509}\\n            \\n            # Test case 3: empty input dictionary\\n            assert compute_idf_weight_dict(100, {}) == {}\\n        \"\"\"\\n        index_2_key_map = {}\\n        index = 0\\n\\n        count_list = []\\n        for key, count in number_dict.items():\\n            index_2_key_map[index] = key\\n            count_list.append(count)\\n            index = index + 1\\n\\n        a = np.array(count_list)\\n        # Smooth to avoid divide by zero error\\n        a = np.log((total_num + 1) / (a + 1))\\n        result = {}\\n\\n        for index, w in enumerate(a):\\n            key = index_2_key_map[index]\\n            result[key] = w\\n\\n        return result', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1735217702, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=1189, prompt_tokens=1445, total_tokens=2634, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))", "test_case_name": "VectorCalculator.txt"}