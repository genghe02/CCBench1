{"response body": "ChatCompletion(id='chatcmpl-AiK7oUruiUrUUQPvwHQunLnwW90ZX', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```python\\n\"\"\"\\nThis class calculates Kappa statistics, which are measures of inter-rater reliability. It \\nincludes methods for calculating Cohen\\'s Kappa and Fleiss\\' Kappa based on contingency \\ntables of ratings from multiple raters.\\n\\nMain functionalities:\\n- The `kappa` method computes Cohen\\'s Kappa statistic for two raters.\\n- The `fleiss_kappa` method computes Fleiss\\' Kappa statistic for multiple raters.\\n\\nDependencies:\\n- Requires NumPy for matrix operations and statistical calculations.\\n\"\"\"\\n\\nimport numpy as np\\n\\nclass KappaCalculator:\\n\\n    @staticmethod\\n    def kappa(testData, k):\\n        \"\"\"\\n        Calculate Cohen\\'s Kappa statistic for two raters based on the provided contingency \\n        table.\\n\\n        Parameters:\\n            testData (list): A list of lists or a 2D list representing the contingency table \\n                             of size k x k.\\n            k (int): The number of categories (ratings).\\n\\n        Returns:\\n            float: Cohen\\'s Kappa statistic, indicating the level of agreement between two raters.\\n        \\n        Test cases:\\n            # Test case 1: Normal use case with 2 categories\\n            input_data = [[50, 10], [5, 35]]\\n            expected_output = 0.6829268292682927\\n            assert kappa(input_data, 2) == expected_output\\n            \\n            # Test case 2: Edge case with all agreements\\n            input_data2 = [[50, 0], [0, 50]]\\n            expected_output2 = 1.0\\n            assert kappa(input_data2, 2) == expected_output2\\n            \\n            # Test case 3: Error case with incorrect input dimensions\\n            input_data3 = [[50, 10, 5], [5, 35, 0]]\\n            try:\\n                kappa(input_data3, 3)\\n            except ValueError:\\n                assert True  # Expecting a ValueError due to incorrect shape           \\n        \"\"\"\\n        dataMat = np.mat(testData)\\n        P0 = 0.0\\n        for i in range(k):\\n            P0 += dataMat[i, i] * 1.0\\n        xsum = np.sum(dataMat, axis=1)\\n        ysum = np.sum(dataMat, axis=0)\\n        sum = np.sum(dataMat)\\n        Pe = float(ysum * xsum) / sum / sum\\n        P0 = float(P0 / sum * 1.0)\\n        cohens_coefficient = float((P0 - Pe) / (1 - Pe))\\n        return cohens_coefficient\\n\\n    @staticmethod\\n    def fleiss_kappa(testData, N, k, n):\\n        \"\"\"\\n        Calculate Fleiss\\' Kappa statistic for multiple raters based on the provided \\n        contingency table.\\n\\n        Parameters:\\n            testData (list): A list of lists or a 2D list representing the ratings for \\n                             N subjects across k categories.\\n            N (int): The number of subjects rated.\\n            k (int): The number of categories (ratings).\\n            n (int): The number of raters.\\n\\n        Returns:\\n            float: Fleiss\\' Kappa statistic, indicating the level of agreement between \\n                   multiple raters.\\n        \\n        Test cases:\\n            # Test case 1: Normal use case with 3 raters and 2 categories\\n            input_data = [[10, 0], [0, 10], [5, 5]]\\n            expected_output = 0.3333333333333333\\n            assert fleiss_kappa(input_data, 3, 2, 6) == expected_output\\n            \\n            # Test case 2: Edge case with complete agreement\\n            input_data2 = [[3, 0], [0, 3], [3, 0]]\\n            expected_output2 = 1.0\\n            assert fleiss_kappa(input_data2, 3, 2, 3) == expected_output2\\n            \\n            # Test case 3: Error case with incorrect input\\n            input_data3 = [[2, 2, 2], [1, 1, 1]]\\n            try:\\n                fleiss_kappa(input_data3, 2, 3, 2)\\n            except ValueError:\\n                assert True  # Expecting a ValueError due to inconsistencies\\n        \"\"\"\\n        dataMat = np.mat(testData, float)\\n        oneMat = np.ones((k, 1))\\n        sum = 0.0\\n        P0 = 0.0\\n        for i in range(N):\\n            temp = 0.0\\n            for j in range(k):\\n                sum += dataMat[i, j]\\n                temp += 1.0 * dataMat[i, j] ** 2\\n            temp -= n\\n            temp /= (n - 1) * n\\n            P0 += temp\\n        P0 = 1.0 * P0 / N\\n        ysum = np.sum(dataMat, axis=0)\\n        for i in range(k):\\n            ysum[0, i] = (ysum[0, i] / sum) ** 2\\n        Pe = ysum * oneMat * 1.0\\n        ans = (P0 - Pe) / (1 - Pe)\\n        return ans[0, 0]\\n```', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1735127156, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier=None, system_fingerprint='fp_d02d531b47', usage=CompletionUsage(completion_tokens=1112, prompt_tokens=1644, total_tokens=2756, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))", "test_case_name": "KappaCalculator.txt"}